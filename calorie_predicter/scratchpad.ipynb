{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd809d0d-bbed-4b51-aa48-89969c500204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from processing_functions import round_up_to_nearest, round_down_to_nearest, filter_calories, sorted_binned_encoding, collapsing_to_priority\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e60a329e-9b24-4a8f-8bed-9115386e53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../recipes.csv')\n",
    "\n",
    "#dropping duplicates from recipe name (which is the label column) because some sources give the same recipes\n",
    "df = raw_df.drop_duplicates('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "777a4ed0-3cc0-4a46-beb7-306143980bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling target variable first\n",
    "calories_df = df['calories']\n",
    "\n",
    "#capping the calorie count, so we will include recipes with calorie counts so that we maintain 90% of our data\n",
    "filtered_calories_df = filter_calories(df, column='calories', quartile_percent=0.9)\n",
    "max_calorie_cutoff = round_up_to_nearest(max(filtered_calories_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5bea9ef-d77d-447d-ac22-f8cd84e68d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning the calorie count to turn this into a classification problem\n",
    "bin_edges = [i for i in range(0, int(max_calorie_cutoff)+1, 300)]\n",
    "labels = [f\"{bin_edges[i]}-{bin_edges[i+1]-1}\" for i in range(len(bin_edges)-1)]\n",
    "binned_calories = pd.cut(filtered_calories_df, bins=bin_edges, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9d11936-3734-4ed3-b1f9-fc36709972cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_calories = binned_calories.rename('binnedCalories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c9306e14-3a88-4081-aac2-42b40c118487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming binned_calories is a pandas Series or DataFrame\n",
    "assert binned_calories.isna().sum() == 0, \"The count of NaN values in binned_calories is not equal to 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8d8d5b11-d6ba-4f2a-b9d6-8b145d3527de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = sorted_binned_encoding(binned_calories)\n",
    "target = binned_calories.map(label_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00791022-da65-464e-87c1-792aae0284d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10494, 22)\n"
     ]
    }
   ],
   "source": [
    "binned_calories_df = df.loc[target.index]\n",
    "\n",
    "print(binned_calories_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97baa5b7-d76f-43af-b4fd-c53a433a7514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10494, 23)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_calories_df = pd.concat([binned_calories_df, target], axis=1)\n",
    "binned_calories_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcf84f-2236-49e8-be38-c89dd46df3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2c67e0c-6d03-42ac-aeca-2628cc2fae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "569aafb5-e5fe-480c-8621-ddd3e1856817",
   "metadata": {},
   "outputs": [],
   "source": [
    "dishType_df = binned_calories_df.dropna(subset=['dishType'])\n",
    "dishType_df = dishType_df['dishType'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec76296e-34c1-4af0-aff0-152542afa309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(df, column):\n",
    "    df.loc[df[column].isna(), column] = '[]'\n",
    "    labels_lst = []\n",
    "    for label in df[column].apply(ast.literal_eval):\n",
    "        labels_lst += label\n",
    "    return labels_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69bdba01-4745-484e-9307-b5305ef45d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'main course': 3381,\n",
       "         'starter': 1757,\n",
       "         'condiments and sauces': 1217,\n",
       "         'desserts': 1080,\n",
       "         'salad': 1023,\n",
       "         'sandwiches': 416,\n",
       "         'soup': 411,\n",
       "         'drinks': 377,\n",
       "         'bread': 251,\n",
       "         'cereals': 206,\n",
       "         'alcohol cocktail': 168,\n",
       "         'biscuits and cookies': 116,\n",
       "         'pancake': 81,\n",
       "         'egg': 40,\n",
       "         'preserve': 11,\n",
       "         'special occasions': 11,\n",
       "         'omelet': 7,\n",
       "         'christmas': 7,\n",
       "         'preps': 6,\n",
       "         'thanksgiving': 2,\n",
       "         'new year': 1,\n",
       "         'cinco de mayo': 1})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(get_values(binned_calories_df, 'dishType'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94c05c0e-a82c-4727-b5a1-d8ea2307bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_list_dish_type = [\n",
    "    'main course',\n",
    "    'starter',\n",
    "    'salad',\n",
    "    'soup',\n",
    "    'drinks',\n",
    "    'bread',\n",
    "    'desserts',\n",
    "    'condiments and sauces',\n",
    "    'sandwiches',\n",
    "    'cereals',\n",
    "    'alcohol cocktail',\n",
    "    'biscuits and cookies',\n",
    "    'pancake',\n",
    "    'egg',\n",
    "    'preserve',\n",
    "    'omelet',\n",
    "    'special occasions',\n",
    "    'christmas',\n",
    "    'preps',\n",
    "    'thanksgiving',\n",
    "    'cinco de mayo'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d31ef15-ed68-4faf-b604-1cef48d48f62",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3484438017.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[94], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    for dish_type in\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "new_dish_type_df = []\n",
    "for dish_type_lst in dishType_df:\n",
    "    if len(dish_type_lst) == 1:\n",
    "        new_dish_type_df.append(dish_type_lst[0])\n",
    "    else:\n",
    "        for priority_dish_type in priority_list_dish_type:\n",
    "            for dish_type in \n",
    "            if priority_dish_type in dish_type_lst:\n",
    "                new_dish_type_df.append(priority_dish_type)\n",
    "                break\n",
    "            else:\n",
    "                #if for some reason none of the dish types in the list are in the priority list, just append mainn course which is the most frequent\n",
    "                new_dish_type_df.append(priority_list_dish_type[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d76563d-4bc5-46aa-a302-f30e405f90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapsing_to_priority_test(type_lst, priority_list):\n",
    "    if len(type_lst) == 1:\n",
    "        return type_lst[0]\n",
    "    else:\n",
    "        for priority_item in priority_list:\n",
    "            for item in type_lst:\n",
    "                if priority_item == item:\n",
    "                    return item\n",
    "        else:\n",
    "            warnings.warn(\"No item in the priority list was found, returning the first priority list item.\")\n",
    "            return priority_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db2d390c-1bc4-42f4-8055-e52e01b842ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'main course': 3381,\n",
       "         'starter': 1744,\n",
       "         'condiments and sauces': 1207,\n",
       "         'desserts': 1068,\n",
       "         'salad': 970,\n",
       "         'sandwiches': 407,\n",
       "         'soup': 394,\n",
       "         'drinks': 377,\n",
       "         'bread': 250,\n",
       "         'cereals': 204,\n",
       "         'alcohol cocktail': 168,\n",
       "         'biscuits and cookies': 116,\n",
       "         'pancake': 81,\n",
       "         'preserve': 11,\n",
       "         'preps': 5,\n",
       "         'special occasions': 2})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([collapsing_to_priority_test(dish_lst, priority_list_dish_type) for dish_lst in dishType_df.to_list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c019b0f-46be-4705-8315-19eab24218f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaviB\\GitHub\\FlavorQuasar\\calorie_predicter\\processing_functions.py:73: UserWarning: cinco de mayo was not found in the priority list, returning the first priority list item.\n",
      "  warnings.warn(\"{} was not found in the priority list, returning the first priority list item.\".format(priority_item))\n"
     ]
    }
   ],
   "source": [
    "binned_calories_df = binned_calories_df.dropna(subset=['dishType'])\n",
    "dishType_df = binned_calories_df['dishType'].apply(ast.literal_eval)\n",
    "dishType_df = dishType_df.rename('dishTypeLabel')\n",
    "\n",
    "dishType_df = dishType_df.apply(lambda x: collapsing_to_priority(x, priority_list_dish_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "55564ba7-66ff-48f3-b502-f3d88722d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10494,)\n"
     ]
    }
   ],
   "source": [
    "pre_processed_df = pd.concat([binned_calories_df, dishType_df], axis=1)\n",
    "print(dishType_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "81297616-8c03-4d46-9ca1-a5704f0161e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uri', 'label', 'image', 'source', 'url', 'shareAs', 'yield',\n",
       "       'dietLabels', 'healthLabels', 'cautions', 'ingredientLines',\n",
       "       'ingredients', 'calories', 'totalWeight', 'totalTime', 'cuisineType',\n",
       "       'mealType', 'dishType', 'totalNutrients', 'totalDaily', 'digest',\n",
       "       'tags', 'binnedCalories', 'dishTypeLabel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "61958c83-0180-4fe7-9f3d-90f7703e7396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dishTypeLabel\n",
       "alcohol cocktail         0.884605\n",
       "biscuits and cookies    -0.204065\n",
       "bread                    0.189855\n",
       "cereals                  1.315521\n",
       "condiments and sauces    0.739704\n",
       "desserts                 0.386819\n",
       "drinks                   1.554733\n",
       "main course              0.520799\n",
       "pancake                  0.277986\n",
       "preps                    0.593710\n",
       "preserve                 0.583254\n",
       "salad                    0.926322\n",
       "sandwiches               0.637394\n",
       "soup                     0.585448\n",
       "starter                  0.776458\n",
       "Name: calories, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness_by_category = pre_processed_df.groupby('dishTypeLabel')['calories'].skew()\n",
    "skewness_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d56a0e59-499b-41e6-9b85-9e35921d71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness_min = skewness_by_category.min()\n",
    "skewness_max = skewness_by_category.max()\n",
    "\n",
    "interval_width = (skewness_max - skewness_min) / 3\n",
    "bin1_end = skewness_min + interval_width\n",
    "bin2_end = bin1_end + interval_width\n",
    "\n",
    "bins = {\n",
    "    'Left Skewed (Higher Calories)': skewness_by_category[(skewness_by_category >= skewness_min) & (skewness_by_category < bin1_end)],\n",
    "    'Approximately Symmetric (Normal Calories)': skewness_by_category[(skewness_by_category >= bin1_end) & (skewness_by_category < bin2_end)],\n",
    "    'Right Skewed (Lower Calories)': skewness_by_category[skewness_by_category >= bin2_end]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f769067c-31f4-43c2-a522-847c0fe886ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biscuits and cookies': 'Left Skewed (Higher Calories)',\n",
       " 'bread': 'Left Skewed (Higher Calories)',\n",
       " 'pancake': 'Left Skewed (Higher Calories)',\n",
       " 'alcohol cocktail': 'Approximately Symmetric (Normal Calories)',\n",
       " 'condiments and sauces': 'Approximately Symmetric (Normal Calories)',\n",
       " 'desserts': 'Approximately Symmetric (Normal Calories)',\n",
       " 'main course': 'Approximately Symmetric (Normal Calories)',\n",
       " 'preps': 'Approximately Symmetric (Normal Calories)',\n",
       " 'preserve': 'Approximately Symmetric (Normal Calories)',\n",
       " 'salad': 'Approximately Symmetric (Normal Calories)',\n",
       " 'sandwiches': 'Approximately Symmetric (Normal Calories)',\n",
       " 'soup': 'Approximately Symmetric (Normal Calories)',\n",
       " 'starter': 'Approximately Symmetric (Normal Calories)',\n",
       " 'cereals': 'Right Skewed (Lower Calories)',\n",
       " 'drinks': 'Right Skewed (Lower Calories)'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew_map = {}\n",
    "for skew in bins.keys():\n",
    "    for category in bins[skew].index:\n",
    "        skew_map[category] = skew\n",
    "        #print(category)\n",
    "\n",
    "skew_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d18b063-a44d-4056-8b65-07cbe3bc68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df['dishTypeSkewedLabels'] = pre_processed_df['dishTypeLabel'].map(skew_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d4f87c5-0d79-48bd-b3f1-9aacc558dac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Approximately Symmetric (Normal Calories)',\n",
       "       'Right Skewed (Lower Calories)', 'Left Skewed (Higher Calories)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_df['dishTypeSkewedLabels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b869b-56ec-48df-a8fd-23d49f6b75a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "facabbcd-6464-4d62-8cce-56b9f6e551a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = pre_processed_df.dropna(subset=['dishTypeSkewedLabels'])\n",
    "pre_processed_df = pre_processed_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "617bfdbb-4205-4b80-9438-ff020a384b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_type_map = {'Approximately Symmetric (Normal Calories)': 1, 'Right Skewed (Lower Calories)': 0, 'Left Skewed (Higher Calories)': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fb0ec76c-2300-4048-825d-7461047b95a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_df['dishTypeSkewedLabels'].map(dish_type_map).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "492d0849-9d51-49cf-a1d8-af34aed38b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df['dishTypeSkewedLabels'] = pre_processed_df['dishTypeSkewedLabels'].map(dish_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "23a10887-d88f-4b80-a56d-ddc5ada76a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uri', 'label', 'image', 'source', 'url', 'shareAs', 'yield',\n",
       "       'dietLabels', 'healthLabels', 'cautions', 'ingredientLines',\n",
       "       'ingredients', 'calories', 'totalWeight', 'totalTime', 'cuisineType',\n",
       "       'mealType', 'dishType', 'totalNutrients', 'totalDaily', 'digest',\n",
       "       'tags', 'binnedCalories', 'dishTypeLabel', 'dishTypeSkewedLabels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21182cce-ff5e-4b9e-8e28-6cd866e0a6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10492, 25)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7db0e-2a24-4b7f-9dbb-76ab00ed84f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51361302-55d0-4420-b984-7aaab6ada8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018a706e-0107-4b03-a682-29907ff60550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10383, 29)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from processing_functions import round_up_to_nearest, round_down_to_nearest, filter_calories, sorted_binned_encoding, collapsing_to_priority, priority_list_meal_type, priority_list_dish_type, one_hot_encode, remove_stop_words, lemmatization\n",
    "from data_processing import get_target_variable, preprocess_dish_type, preprocess_meal_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f395238f-e999-4583-b315-400b137d8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../recipes.csv')\n",
    "df = raw_df.drop_duplicates('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e200528e-9f1f-49a1-9cfb-2fc7be012383",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = get_target_variable(df)\n",
    "pre_processed_df = preprocess_dish_type(pre_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8469391c-7994-41d5-b617-23db8c245baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mealType_df = pre_processed_df['mealType'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cc0ced-8c8e-4962-a7b1-c5061a4233c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_list_meal_type_var = priority_list_meal_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cee50bc-a715-4f6f-bc5c-e41fcf53ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mealType_df = mealType_df.apply(lambda x: collapsing_to_priority(x, priority_list_meal_type_var))\n",
    "\n",
    "replace_lst = ['brunch', 'teatime']\n",
    "replacement = 'snack'\n",
    "mealType_df = mealType_df.apply(lambda x: replacement if x in replace_lst else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbec9117-2d2d-457f-b7c2-25d2c2618b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mealType_df = mealType_df.rename('mealTypeRefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b12cea2-6ea7-4aaa-9a9f-2d473dcc85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = pd.concat([pre_processed_df, mealType_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e013df7-75b8-4c08-afc4-43dcafdab9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(df, column):\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    \n",
    "    # Fit and transform the column to one-hot encoded format\n",
    "    onehot_encoded = onehot_encoder.fit_transform(df[[column]])\n",
    "    onehot_encoded_array = onehot_encoded.toarray()\n",
    "    onehot_encoded_df = pd.DataFrame(onehot_encoded_array, columns=onehot_encoder.get_feature_names_out([column]))\n",
    "\n",
    "    return onehot_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17446c3d-7d8e-4c22-8679-7a29dd038d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = pd.concat([pre_processed_df, onehot_encoded_df], axis=1)\n",
    "pre_processed_df = pre_processed_df.drop('mealTypeRefined', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39fb7fb7-709b-4165-82e1-6d06c764caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mealTypeRefined_breakfast', 'mealTypeRefined_lunch/dinner',\n",
       "       'mealTypeRefined_snack', 'uri', 'label', 'image', 'source', 'url',\n",
       "       'shareAs', 'yield', 'dietLabels', 'healthLabels', 'cautions',\n",
       "       'ingredientLines', 'ingredients', 'calories', 'totalWeight',\n",
       "       'totalTime', 'cuisineType', 'mealType', 'dishType', 'totalNutrients',\n",
       "       'totalDaily', 'digest', 'tags', 'binnedCalories', 'dishTypeLabel',\n",
       "       'dishTypeSkewedLabels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aff9652e-4099-4448-98bd-37375fbcba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_meal_type(pre_processed_df):\n",
    "    mealType_df = pre_processed_df['mealType'].apply(ast.literal_eval)\n",
    "\n",
    "    #converting multilabel column into single label\n",
    "    priority_list_meal_type_var = priority_list_meal_type()\n",
    "    mealType_df = mealType_df.apply(lambda x: collapsing_to_priority(x, priority_list_meal_type_var))\n",
    "\n",
    "    #replacing brunch and teatime with snack, effectively combining these categories\n",
    "    replace_lst = ['brunch', 'teatime']\n",
    "    replacement = 'snack'\n",
    "    mealType_df = mealType_df.apply(lambda x: replacement if x in replace_lst else x)\n",
    "\n",
    "    mealType_df = mealType_df.rename('mealTypeRefined')\n",
    "    pre_processed_df = pd.concat([pre_processed_df, mealType_df], axis=1)\n",
    "\n",
    "    return pre_processed_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed13679-b293-4c2c-a607-7639bdd84d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = preprocess_meal_type(pre_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee59cdb-b1c5-483b-81bc-c16873b0338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded_df = one_hot_encode(pre_processed_df, 'mealTypeRefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7199ff2d-37e0-49b9-aa52-91f57d4445cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = pd.concat([pre_processed_df, onehot_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae01b17-0c74-4a91-babf-e4f84e123852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cbf2780-98c2-411b-998f-8996fa9884c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1698b9ee-211c-47f0-8ae7-41c96fc7114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_text(df, column, english_stop_words, lemmatizer):\n",
    "    recipes = df[column]\n",
    "    recipes = recipes.apply(lambda x: remove_stop_words(x, english_stop_words))\n",
    "    recipes = recipes.apply(lambda x: lemmatization(x, lemmatizer))\n",
    "    recipes = recipes.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "    df.loc[:, column] = recipes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "934e69be-e628-4e05-befb-793ab06b5215",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpre_process_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_processed_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_stop_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menglish_stop_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlemmatizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mpre_process_text\u001b[1;34m(df, column, english_stop_words, lemmatizer)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpre_process_text\u001b[39m(df, column, english_stop_words, lemmatizer):\n\u001b[0;32m      2\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m df[column]\n\u001b[1;32m----> 3\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m \u001b[43mrecipes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_stop_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_stop_words\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m recipes\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: lemmatization(x, lemmatizer))\n\u001b[0;32m      5\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m recipes\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: word_tokenize(x))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\pandas\\core\\series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4780\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mpre_process_text.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpre_process_text\u001b[39m(df, column, english_stop_words, lemmatizer):\n\u001b[0;32m      2\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m df[column]\n\u001b[1;32m----> 3\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m recipes\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mremove_stop_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_stop_words\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m recipes\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: lemmatization(x, lemmatizer))\n\u001b[0;32m      5\u001b[0m     recipes \u001b[38;5;241m=\u001b[39m recipes\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: word_tokenize(x))\n",
      "File \u001b[1;32m~\\GitHub\\FlavorQuasar\\calorie_predicter\\processing_functions.py:102\u001b[0m, in \u001b[0;36mremove_stop_words\u001b[1;34m(text, english_stop_words)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_stop_words\u001b[39m(text, english_stop_words):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m#get the words in the review as a list\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     text_words \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m#make a new list with the same words but only if they are not a stop word\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     removed_stop_words_list \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text_words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m english_stop_words]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "pre_process_text(df=pre_processed_df, column='label', english_stop_words=english_stop_words, lemmatizer=lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80d94c1-3a6a-4136-9b7f-e95141cbdd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        [Green, Beans]\n",
       "1               [Sauteed, Green, Beans]\n",
       "2           [Caramelized, Green, Beans]\n",
       "3        [Sautéed, Fresh, Green, Beans]\n",
       "4                 [Fancy, Green, Beans]\n",
       "                      ...              \n",
       "10378     [Tuna, melt, pizza, baguette]\n",
       "10379              [Quick, Tuna, Salad]\n",
       "10380          [Savory, Tuna, Sandwich]\n",
       "10381       [Tiny, Tuna, Melts, recipe]\n",
       "10382          [Mexi-Cali, Tuna, Salad]\n",
       "Name: label, Length: 10383, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.loc[:, 'label'] = recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b75090-b1b6-46ee-89bf-fa8ba7ffc9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
