{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f959da6a-8b95-4246-b31f-e6de97aa57de",
   "metadata": {},
   "source": [
    "# Building a Vegan Likelihood Model\n",
    "\n",
    "The goal is to build a model to either predict if a dish is vegan just from the recipe name, or create a scoring model to predict how likely or easily a recipe is or could be vegan.\n",
    "\n",
    "Or rather, we can take the cosine similarity with a user input for a recipe name and out list of recipes from out database, and then use the top score to get the list of ingredients. Then our model can predict how likely the recipe would be vegan. Could just also list out potentially ingredients that would likely show up as non-vegan in this recipe to watch out for.\n",
    "\n",
    "## EDA and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edb738a-2166-4cd7-8b6d-5631c30f035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c42503f-16cb-49ce-b3c3-2515826ad577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('example_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b720add-c477-4217-8d9d-97e5110cf0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uri', 'label', 'image', 'source', 'url', 'shareAs', 'yield',\n",
       "       'dietLabels', 'healthLabels', 'cautions', 'ingredientLines',\n",
       "       'ingredients', 'calories', 'totalWeight', 'totalTime', 'cuisineType',\n",
       "       'mealType', 'dishType', 'totalNutrients', 'totalDaily', 'digest',\n",
       "       'tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefd959d-c5dc-4709-943f-0e53cbb038f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_col = df['ingredients'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b043d24c-6050-4f02-8fb2-3f4e64fb081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '375g/13oz plain flour',\n",
       " 'quantity': 375.0,\n",
       " 'measure': 'gram',\n",
       " 'food': 'flour',\n",
       " 'weight': 375.0,\n",
       " 'foodCategory': 'grains',\n",
       " 'foodId': 'food_ahebfs0a985an4aubqaebbipra58',\n",
       " 'image': 'https://www.edamam.com/food-img/b4c/b4c739e76a6f2172b7ad49d0aa41d5aa.jpg'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_col[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78756df-82f6-4fe2-8067-f931b312e4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = dict()\n",
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44482a36-b494-4773-8084-78836899cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredients_col[1][0]['foodCategory']\n",
    "dct[ingredients_col[1][0]['foodCategory']] = ingredients_col[1][0]['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c034e23b-b270-411b-91ab-cc0455e59d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = dict()\n",
    "for i, row in ingredients_col.items():\n",
    "    for j in range(len(row)):\n",
    "        key = row[j]['foodCategory']\n",
    "        value = row[j]['quantity']\n",
    "\n",
    "        if key in dct.keys():\n",
    "            dct[key] += value\n",
    "        else:\n",
    "            dct[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9fc5a72-a771-40f2-a02f-364f20122004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'text' in ingredients_col[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad943c9-378f-42b0-9689-76d03095326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Eggs', 'Milk', 'Cheese', 'Dairy', 'grains', 'Condiments and sauces', 'condiments and sauces', 'Oils', 'vegetables', 'canned vegetables', 'milk', 'bread, rolls and tortillas', 'cured meats', 'fruit', 'canned grains', 'canned soup', 'bov', 'plant-based protein', 'sugars', 'quick breads and pastries', 'wines', '100% juice', 'water', 'yogurt', 'beer', 'ready-to-eat cereals', 'sugar syrups', 'Cured meats', 'crackers', 'savory snacks', 'liquors and cocktails', 'meats', 'sugar jam', 'Vegan products', 'candy', 'chocolate', None, 'canned fruit', 'non-dairy beverages', 'flavored water', 'cocktails and liquors', 'canned seafood', 'seafood', 'Poultry', 'sweetened beverages', 'pastries', 'frozen treats', 'coffee and tea', 'eggs', 'cooked grains', 'Plant-based protein', 'frozen grained based', 'mixed grains', 'sandwhiches', 'protein and nutritional powders', 'salads'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c26829e-9dd6-4c08-bd3d-2937eface087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil, '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_s = ''\n",
    "ex_s_lst = ast.literal_eval(df.iloc[0]['ingredientLines'])\n",
    "for s in ex_s_lst:\n",
    "    ex_s += s + ', '\n",
    "\n",
    "ex_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3a37ec-a80a-4275-9465-7c2ca754aa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(ex_s_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc99227-97c1-4425-89ab-e835457f358f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b177d98-79f5-469b-b69a-1b7d09974a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a2f5e2-44d1-4bc5-8c18-1d45acf3b535",
   "metadata": {},
   "source": [
    "## Preprocessing for Transformer\n",
    "\n",
    "Going to try to preprocess data to take the dish/recipe name (`label` column) and the `healthLabel` as input, and output the ingredients list as a long string. We can use a transformer for this to output the recipe's ingredients in long text form. \n",
    "\n",
    "The `healthLabel` will only be a select few options though, and the user can only select 1 for now, from: ['Mediterranean', 'Vegetarian', 'Vegan', 'Red-Meat-Free', 'Paleo', 'Pescatarian']. When reducing the healthLabels column from multilabel to categorical, we need to define a priority order, and if none of these are there then the dish is balanced, so we will add that as an option. In the future, some analysis on this column should be done to improve the priority order, rather than relying on domain knowledge. Alternatively, and option to select multiple could be implemented instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9c6f09a-f93f-4da7-8221-749d8bbafb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_order = ['Vegan', 'Vegetarian', 'Pescatarian', 'Paleo', 'Red-Meat-Free', 'Mediterranean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58cce8a8-8151-4c94-aafd-227a9a869137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "1       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "2       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "3       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "4       [Vegetarian, Pescatarian, Egg-Free, Peanut-Fre...\n",
       "                              ...                        \n",
       "1195    [Keto-Friendly, Pescatarian, Mediterranean, Gl...\n",
       "1196    [Pescatarian, Gluten-Free, Wheat-Free, Egg-Fre...\n",
       "1197    [Sugar-Conscious, Keto-Friendly, Pescatarian, ...\n",
       "1198    [Sugar-Conscious, Keto-Friendly, Pescatarian, ...\n",
       "1199    [Sugar-Conscious, Pescatarian, Mediterranean, ...\n",
       "Name: healthLabels, Length: 1200, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_labels = df['healthLabels'].apply(ast.literal_eval)\n",
    "health_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e874203-9b73-452c-8ca8-3486f89194a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_priority(labels):\n",
    "    for label in priority_order:\n",
    "        if label in labels:\n",
    "            return label\n",
    "    return 'Balanced'  # Handle case where no label matches priority_order, in which case the diet is balanced\n",
    "\n",
    "# Apply function to the multilabels series\n",
    "diet_type = health_labels.apply(replace_with_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa78ee3-5e60-4ac1-bccb-18652857abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vegetarian       400\n",
       "Vegan            279\n",
       "Pescatarian      209\n",
       "Balanced         181\n",
       "Red-Meat-Free     57\n",
       "Paleo             42\n",
       "Mediterranean     32\n",
       "Name: healthLabels, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068e884-2b21-45a4-98b9-7273114f9141",
   "metadata": {},
   "source": [
    "Now we have our dietary preference column. The recipe name is fine as is so next is the ingredients list which is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cea2701-1126-46b3-b274-b649de8b9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_name = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec883fa-1abb-43b8-bec6-e58d3b694e2e",
   "metadata": {},
   "source": [
    "We need to just join these lists of strings with commas so they be user friendly to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63f43efe-cf87-4441-a004-7bc40cf2401a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1 organic large egg, 1 teaspoon whole milk or ...\n",
       "1       375g/13oz plain flour, Pinch salt, 225g/8oz bu...\n",
       "2       1 cup asiago cheese, grated, 1 cup fontina che...\n",
       "3       4 ounces, weight Cream Cheese, Softened, 1/2 c...\n",
       "4       8 ounces elbow pasta, 1/4 cup unsalted butter,...\n",
       "                              ...                        \n",
       "1195    4 (6 ounce) tilapia fillets, salt, pepper, 1/2...\n",
       "1196    * 1 Vegetable oil cooking spray, * 4 U.S.-farm...\n",
       "1197    2 tbsp chopped red onion, 1 tbsp olive oil, 1 ...\n",
       "1198    3 tablespoons unsalted butter, 2 tablespoons e...\n",
       "1199    * 2 tilapia fillets (skinless, about 4 ounces ...\n",
       "Name: ingredientLines, Length: 1200, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_lst = df['ingredientLines'].apply(ast.literal_eval)\n",
    "ingredients_lst = ingredients_lst.apply(lambda x: ', '.join(x))\n",
    "ingredients_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83e4d7-0b6d-4067-80db-90a4beb405dc",
   "metadata": {},
   "source": [
    "Now we can make our dataframe for the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d95c300-2ddf-405b-bdc3-6202a792e31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dietType</th>\n",
       "      <th>recipeName</th>\n",
       "      <th>ingredientsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Cheese Omelette</td>\n",
       "      <td>1 organic large egg, 1 teaspoon whole milk or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Cheese straws</td>\n",
       "      <td>375g/13oz plain flour, Pinch salt, 225g/8oz bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>CHEESE GOOP</td>\n",
       "      <td>1 cup asiago cheese, grated, 1 cup fontina che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Pimento Cheese</td>\n",
       "      <td>4 ounces, weight Cream Cheese, Softened, 1/2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Five Cheese Skillet Mac and Cheese recipes</td>\n",
       "      <td>8 ounces elbow pasta, 1/4 cup unsalted butter,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dietType                                  recipeName  \\\n",
       "0  Vegetarian                             Cheese Omelette   \n",
       "1  Vegetarian                               Cheese straws   \n",
       "2  Vegetarian                                 CHEESE GOOP   \n",
       "3  Vegetarian                              Pimento Cheese   \n",
       "4  Vegetarian  Five Cheese Skillet Mac and Cheese recipes   \n",
       "\n",
       "                                     ingredientsList  \n",
       "0  1 organic large egg, 1 teaspoon whole milk or ...  \n",
       "1  375g/13oz plain flour, Pinch salt, 225g/8oz bu...  \n",
       "2  1 cup asiago cheese, grated, 1 cup fontina che...  \n",
       "3  4 ounces, weight Cream Cheese, Softened, 1/2 c...  \n",
       "4  8 ounces elbow pasta, 1/4 cup unsalted butter,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([diet_type, recipe_name, ingredients_lst], axis = 1)\n",
    "column_names = {'healthLabels': 'dietType', 'label': 'recipeName', 'ingredientLines': 'ingredientsList'}\n",
    "df2 = df2.rename(columns=column_names)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce3170-0a84-48b4-bf52-70340f609b74",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa471d8-e24d-41a3-ad6b-65c7d7c3f79c",
   "metadata": {},
   "source": [
    "### Gretel\n",
    "\n",
    "https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/conditional_text_generation_with_gpt.ipynb#scrollTo=YMg9nX6SczHe\n",
    "\n",
    "https://gretel.ai/blog/conditional-text-generation-by-fine-tuning-gretel-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08200302-9632-4b54-9c5c-ae98bc23aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client import configure_session\n",
    "from gretel_client.helpers import poll\n",
    "from gretel_client.projects import create_or_get_unique_project, get_project\n",
    "from gretel_client.projects.models import read_model_config, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f4f5e00-af03-4f5f-8492-c3f0f3c2e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = \"gretelai/mpt-7b\"  # @param {type:\"string\"}\n",
    "GRETEL_PROJECT = 'edamam'  # @param {type:\"string\"}\n",
    "TEXT_COLUMN = \"text\"# @param {type:\"string\"}\n",
    "LABEL_COLUMN = \"ingredientsList\" # @param {type:\"string\"}\n",
    "LABEL_AND_TEXT_COLUMN = 'recipeTypeName'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1dc0fe5-65be-4826-80d4-d7081bf54754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schema_version': '1.0',\n",
       " 'name': 'natural-language-gpt',\n",
       " 'models': [{'gpt_x': {'data_source': '__temp__',\n",
       "    'pretrained_model': 'gretelai/mpt-7b',\n",
       "    'column_name': 'recipeTypeName',\n",
       "    'params': {'batch_size': 4,\n",
       "     'steps': 750,\n",
       "     'weight_decay': 0.01,\n",
       "     'warmup_steps': 100,\n",
       "     'lr_scheduler': 'linear',\n",
       "     'learning_rate': 0.0002},\n",
       "    'generate': {'num_records': 80, 'maximum_text_length': 100}}}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = read_model_config(\"synthetics/natural-language\")\n",
    "config['models'][0]['gpt_x']['pretrained_model'] = LLM\n",
    "config['models'][0]['gpt_x']['column_name'] = LABEL_AND_TEXT_COLUMN\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2da52d18-f906-463b-9920-5f51afd53491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Gretel Api Key ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config file C:\\Users\\RaviB\\.gretel\\config.json is group- and/or world-readable!\n",
      "Setting permissions to be readable by the owner only.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching Gretel config to disk.\n",
      "Using endpoint https://api.gretel.cloud\n",
      "Logged in as ravinderbrai@gmail.com ✅\n"
     ]
    }
   ],
   "source": [
    "configure_session(api_key=\"prompt\", cache=\"yes\", endpoint=\"https://api.gretel.cloud\", validate=True, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41fab7a3-c9e2-4147-bf8f-d59a6e02785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = create_or_get_unique_project(name=GRETEL_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7294644-425f-4820-81cd-66c08a96de3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipeTypeName</th>\n",
       "      <th>ingredientsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegetarian Cheese Omelette</td>\n",
       "      <td>1 organic large egg, 1 teaspoon whole milk or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegetarian Cheese straws</td>\n",
       "      <td>375g/13oz plain flour, Pinch salt, 225g/8oz bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian CHEESE GOOP</td>\n",
       "      <td>1 cup asiago cheese, grated, 1 cup fontina che...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               recipeTypeName  \\\n",
       "0  Vegetarian Cheese Omelette   \n",
       "1    Vegetarian Cheese straws   \n",
       "2      Vegetarian CHEESE GOOP   \n",
       "\n",
       "                                     ingredientsList  \n",
       "0  1 organic large egg, 1 teaspoon whole milk or ...  \n",
       "1  375g/13oz plain flour, Pinch salt, 225g/8oz bu...  \n",
       "2  1 cup asiago cheese, grated, 1 cup fontina che...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.concat([df2['dietType'] + ' ' + df2['recipeName'], df2['ingredientsList']], axis = 1)\n",
    "df3 = df3.rename(columns={0: 'recipeTypeName'})\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21043479-bddc-4fc1-a38e-ba356e5c6d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow along with training in the console: https://console.gretel.ai/proj_2c86dkC0SVcsijB19WyuyyBDU9L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting poller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"uid\": \"65c618ccfdff8e43a5ba293a\",\n",
      "    \"guid\": \"model_2c87L94yO3kjdN97XnZcn7bSkK2\",\n",
      "    \"model_name\": \"edamam-gretelai/mpt-7b\",\n",
      "    \"model_key\": \"\",\n",
      "    \"runner_mode\": \"cloud\",\n",
      "    \"user_id\": \"65c58885ece628960a93314c\",\n",
      "    \"user_guid\": \"user_2c6uTY9yUSoUHG8IgV8qYGvL9F6\",\n",
      "    \"billing_domain\": null,\n",
      "    \"billing_domain_guid\": null,\n",
      "    \"project_id\": \"65c61773c22c3df5e1726865\",\n",
      "    \"project_guid\": \"proj_2c86dkC0SVcsijB19WyuyyBDU9L\",\n",
      "    \"cluster_guid\": null,\n",
      "    \"status_history\": {\n",
      "        \"created\": \"2024-02-09T12:21:32.831198Z\"\n",
      "    },\n",
      "    \"last_modified\": \"2024-02-09T12:21:32.897097Z\",\n",
      "    \"status\": \"created\",\n",
      "    \"last_active_hb\": null,\n",
      "    \"duration_minutes\": null,\n",
      "    \"error_msg\": null,\n",
      "    \"error_id\": null,\n",
      "    \"traceback\": null,\n",
      "    \"annotations\": null,\n",
      "    \"provenance\": null,\n",
      "    \"container_image\": \"074762682575.dkr.ecr.us-west-2.amazonaws.com/models/gpt_x@sha256:893f53dfe4f500e1f64bf1064c5370a3da5886f70db184bafa300461b8f59820\",\n",
      "    \"container_image_version\": \"2.10.108\",\n",
      "    \"model_type\": \"gpt_x\",\n",
      "    \"model_type_alias\": null,\n",
      "    \"project_name\": \"edamam\",\n",
      "    \"config\": {\n",
      "        \"schema_version\": \"1.0\",\n",
      "        \"name\": \"edamam-gretelai/mpt-7b\",\n",
      "        \"models\": [\n",
      "            {\n",
      "                \"gpt_x\": {\n",
      "                    \"data_source\": [\n",
      "                        \"gretel_973d27d0b3e6466ba31ad588f4703401_dataframe-864babbe-7a05-4e33-b64d-f63a17ca7e96.csv\"\n",
      "                    ],\n",
      "                    \"ref_data\": {},\n",
      "                    \"pretrained_model\": \"gretelai/mpt-7b\",\n",
      "                    \"prompt_template\": null,\n",
      "                    \"column_name\": \"recipeTypeName\",\n",
      "                    \"validation\": null,\n",
      "                    \"params\": {\n",
      "                        \"batch_size\": 4,\n",
      "                        \"epochs\": null,\n",
      "                        \"steps\": 750,\n",
      "                        \"weight_decay\": 0.01,\n",
      "                        \"warmup_steps\": 100,\n",
      "                        \"lr_scheduler\": \"linear\",\n",
      "                        \"learning_rate\": 0.0002,\n",
      "                        \"max_tokens\": 512\n",
      "                    },\n",
      "                    \"generate\": {\n",
      "                        \"num_records\": 80,\n",
      "                        \"seed_records_multiplier\": 1,\n",
      "                        \"maximum_text_length\": 100,\n",
      "                        \"top_p\": 0.8987601335810778,\n",
      "                        \"top_k\": 43,\n",
      "                        \"num_beams\": 1,\n",
      "                        \"do_sample\": true,\n",
      "                        \"do_early_stopping\": true,\n",
      "                        \"typical_p\": 0.8,\n",
      "                        \"temperature\": null\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"notifications\": null,\n",
      "        \"label_predictors\": null\n",
      "    },\n",
      "    \"autouse_config\": null,\n",
      "    \"autouse_handler_id\": null,\n",
      "    \"auth_source\": \"grtu\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Status is created. Model creation has been queued.\n",
      "INFO: Status is pending. A Gretel Cloud worker is being allocated to begin model creation.\n",
      "INFO: Status is active. A worker has started creating your model!\n",
      "2024-02-09T12:21:54.400419Z  Resolved revision for model\n",
      "{\n",
      "    \"revision\": \"4a89ac4fb5c17e714cc27967728b2edd0a401516\",\n",
      "    \"model\": \"gretelai/mpt-7b\"\n",
      "}\n",
      "2024-02-09T12:21:54.400972Z  Parameter efficient fine tuning (PEFT) methods will be used, which greatly reduce the number of trainable parameters.\n",
      "2024-02-09T12:21:54.404917Z  Starting GPT model training...\n",
      "{\n",
      "    \"num_train_steps\": 750\n",
      "}\n",
      "2024-02-09T12:21:54.405266Z  Fine-tuning 'gretelai/mpt-7b' with provided dataset!\n",
      "2024-02-09T12:21:54.405503Z  Disclaimer: the chosen model may produce untrue and/or offensive content without warning. For more info, see https://docs.gretel.ai/reference/synthetics/models/gretel-gpt#limitations-and-biases\n",
      "2024-02-09T12:21:54.405849Z  Downloading model from remote source. Depending on the size of the model, this may take a few minutes.\n",
      "2024-02-09T12:22:54.406381Z  Model download 73% complete, ETA 23s (9643812960/13300902259 bytes downloaded)\n",
      "2024-02-09T12:23:23.188320Z  Model download 100% complete (13300902259 bytes downloaded). Loading model onto GPU ...\n",
      "2024-02-09T12:23:54.411582Z  Still loading model ...\n",
      "2024-02-09T12:24:54.420751Z  Still loading model ...\n",
      "2024-02-09T12:25:54.421524Z  Still loading model ...\n",
      "2024-02-09T12:26:08.910884Z  Successfully loaded model and tokenizer.\n",
      "2024-02-09T12:26:08.913131Z  PEFT trainable params: 4194304 || all params: 6653480960 || trainable%: 0.0630392425441013\n",
      "2024-02-09T12:27:11.367536Z  Training in progress, 16.0% complete (step 120/750, ETA 324s)\n",
      "{\n",
      "    \"loss\": 4.3908,\n",
      "    \"learning_rate\": 3e-05,\n",
      "    \"epoch\": 0.4,\n",
      "    \"step\": 120\n",
      "}\n",
      "2024-02-09T12:28:13.938029Z  Training in progress, 33.1% complete (step 248/750, ETA 251s)\n",
      "{\n",
      "    \"loss\": 3.6744,\n",
      "    \"learning_rate\": 6.2e-05,\n",
      "    \"epoch\": 0.83,\n",
      "    \"step\": 248\n",
      "}\n",
      "2024-02-09T12:28:39.301273Z  Training in progress, 39.5% complete (step 296/750, ETA 229s)\n",
      "{\n",
      "    \"loss\": 3.2509,\n",
      "    \"learning_rate\": 7.4e-05,\n",
      "    \"epoch\": 0.99,\n",
      "    \"step\": 296\n",
      "}\n",
      "2024-02-09T12:29:43.644159Z  Training in progress, 57.6% complete (step 432/750, ETA 157s)\n",
      "{\n",
      "    \"loss\": 2.4238,\n",
      "    \"learning_rate\": 0.00010800000000000001,\n",
      "    \"epoch\": 1.44,\n",
      "    \"step\": 432\n",
      "}\n",
      "2024-02-09T12:30:46.006006Z  Training in progress, 74.7% complete (step 560/750, ETA 94s)\n",
      "{\n",
      "    \"loss\": 2.0013,\n",
      "    \"learning_rate\": 0.000138,\n",
      "    \"epoch\": 1.87,\n",
      "    \"step\": 560\n",
      "}\n",
      "2024-02-09T12:31:05.506610Z  Training in progress, 80.0% complete (step 600/750, ETA 74s)\n",
      "{\n",
      "    \"loss\": 1.8356,\n",
      "    \"learning_rate\": 0.000148,\n",
      "    \"epoch\": 2.0,\n",
      "    \"step\": 600\n",
      "}\n",
      "2024-02-09T12:32:08.007262Z  Training in progress, 97.1% complete (step 728/750, ETA 11s)\n",
      "{\n",
      "    \"loss\": 1.7706,\n",
      "    \"learning_rate\": 0.00018,\n",
      "    \"epoch\": 2.43,\n",
      "    \"step\": 728\n",
      "}\n",
      "2024-02-09T12:32:19.695407Z  Training in progress, 100.0% complete (step 750/750, ETA 0s)\n",
      "{\n",
      "    \"loss\": 1.8153,\n",
      "    \"learning_rate\": 0.00018600000000000002,\n",
      "    \"epoch\": 2.51,\n",
      "    \"step\": 750\n",
      "}\n",
      "2024-02-09T12:32:19.695991Z  Training in progress, 100.0% complete (step 750/750, ETA 0s)\n",
      "{\n",
      "    \"train_runtime\": 369.9767,\n",
      "    \"train_samples_per_second\": 8.13,\n",
      "    \"train_steps_per_second\": 0.254,\n",
      "    \"train_loss\": 2.7695447231860872,\n",
      "    \"epoch\": 2.51,\n",
      "    \"step\": 750\n",
      "}\n",
      "2024-02-09T12:32:19.696843Z  Training is completed!\n",
      "2024-02-09T12:32:19.697275Z  GPT model training complete.\n",
      "2024-02-09T12:32:19.697731Z  Saving model\n",
      "2024-02-09T12:32:19.742514Z  Sampling 80 records using auto prompting.\n",
      "2024-02-09T12:32:19.744141Z  Using device 'cuda'\n",
      "2024-02-09T12:32:19.915207Z  Generating records...\n",
      "{\n",
      "    \"num_records\": 80\n",
      "}\n",
      "2024-02-09T12:32:29.071456Z  Successfully generated 80 records\n",
      "2024-02-09T12:32:29.081486Z  Creating Synthetic Text Data Quality Report...\n",
      "2024-02-09T12:32:29.081818Z  Creating text metrics report...\n",
      "2024-02-09T12:32:39.853649Z  Finished creating text metrics report.\n",
      "2024-02-09T12:32:39.869477Z  Synthetic Text Data Quality Report finished, exporting report artifacts...\n",
      "2024-02-09T12:32:39.870591Z  Model has been created successfully\n",
      "2024-02-09T12:32:42.079676Z  Uploading artifacts to Gretel Cloud...\n",
      "2024-02-09T12:32:43.392112Z  Upload to Gretel Cloud is completed.\n"
     ]
    }
   ],
   "source": [
    "model = project.create_model_obj(model_config=config, data_source=df3)\n",
    "print(f\"Follow along with training in the console: {project.get_console_url()}\")\n",
    "model.name = f\"{GRETEL_PROJECT}-{LLM}\"\n",
    "model.submit_cloud()\n",
    "\n",
    "poll(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "706ba397-8bf1-4111-8b8a-e9c97788862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LABEL = \"Vegan Carrot Juice\"  # @param {type:\"string\"}\n",
    "NUM_RECORDS = 5  # @param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cf2647c-3787-43a0-b222-5346b3bd7425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text completion prompts with class labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               prompt\n",
       "0  Vegan Carrot Juice\n",
       "1  Vegan Carrot Juice\n",
       "2  Vegan Carrot Juice\n",
       "3  Vegan Carrot Juice\n",
       "4  Vegan Carrot Juice"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_prompt_df(prompt_label: str, num_records: int = 25) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a prompt DataFrame with the given number of rows, each containing a prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt_label (str): The class label to use in the prompt.\n",
    "        num_records (int): The number of records to generate in the prompt DataFrame.\n",
    "            The generated synthetic data will have the same number of records.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the given number of rows, each containing a class\n",
    "            label prompt.\n",
    "    \"\"\"\n",
    "    # Note: the column name in this dataframe doesn't matter, as it may only contain a single\n",
    "    # column anyway.\n",
    "    # The column name in the generated synthetic data will be taken from the training dataset\n",
    "    # instead.\n",
    "    return pd.DataFrame([prompt_label] * num_records, columns=[\"prompt\"])\n",
    "\n",
    "\n",
    "print(\"Text completion prompts with class labels\")\n",
    "prompt_df = create_prompt_df(PROMPT_LABEL, num_records=NUM_RECORDS)\n",
    "prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67d445e3-5977-400d-b211-32f28f53a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_handler = model.create_record_handler_obj(\n",
    "        params={\"maximum_text_length\": 100, \"temperature\": 0.7},\n",
    "        data_source=prompt_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ef6dc19-dda7-4986-ab93-aeaa1f3e9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting poller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"uid\": \"65c61cf766d154ace237a255\",\n",
      "    \"guid\": \"model_run_2c89VDPpveIi7YZFnV4GWbdlH5q\",\n",
      "    \"model_name\": null,\n",
      "    \"model_key\": \"\",\n",
      "    \"runner_mode\": \"cloud\",\n",
      "    \"user_id\": \"65c58885ece628960a93314c\",\n",
      "    \"user_guid\": \"user_2c6uTY9yUSoUHG8IgV8qYGvL9F6\",\n",
      "    \"billing_domain\": null,\n",
      "    \"billing_domain_guid\": null,\n",
      "    \"project_id\": \"65c61773c22c3df5e1726865\",\n",
      "    \"project_guid\": \"proj_2c86dkC0SVcsijB19WyuyyBDU9L\",\n",
      "    \"cluster_guid\": null,\n",
      "    \"status_history\": {\n",
      "        \"created\": \"2024-02-09T12:39:19.717000Z\"\n",
      "    },\n",
      "    \"last_modified\": \"2024-02-09T12:39:19.861000Z\",\n",
      "    \"status\": \"created\",\n",
      "    \"last_active_hb\": null,\n",
      "    \"duration_minutes\": null,\n",
      "    \"error_msg\": null,\n",
      "    \"error_id\": null,\n",
      "    \"traceback\": null,\n",
      "    \"annotations\": null,\n",
      "    \"provenance\": null,\n",
      "    \"container_image\": \"074762682575.dkr.ecr.us-west-2.amazonaws.com/models/gpt_x@sha256:893f53dfe4f500e1f64bf1064c5370a3da5886f70db184bafa300461b8f59820\",\n",
      "    \"container_image_version\": \"2.10.108\",\n",
      "    \"model_id\": \"65c618ccfdff8e43a5ba293a\",\n",
      "    \"model_guid\": \"model_2c87L94yO3kjdN97XnZcn7bSkK2\",\n",
      "    \"model_type\": \"gpt_x\",\n",
      "    \"action\": \"gpt_x_run\",\n",
      "    \"config\": {\n",
      "        \"data_source\": \"gretel_2edf976b56e143ec8407496d79710f73_dataframe-086fc73b-a166-4dca-b694-bb85c6b0e576.csv\",\n",
      "        \"ref_data\": {},\n",
      "        \"params\": {\n",
      "            \"num_records\": null,\n",
      "            \"seed_records_multiplier\": 1,\n",
      "            \"maximum_text_length\": 100,\n",
      "            \"top_p\": 0.8987601335810778,\n",
      "            \"top_k\": 43,\n",
      "            \"num_beams\": 1,\n",
      "            \"do_sample\": true,\n",
      "            \"do_early_stopping\": true,\n",
      "            \"typical_p\": 0.8,\n",
      "            \"temperature\": 0.7,\n",
      "            \"num_records_multiplier\": null,\n",
      "            \"prompt\": null\n",
      "        }\n",
      "    },\n",
      "    \"is_autouse\": false,\n",
      "    \"auth_source\": \"grtu\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Status is created. A job has been queued.\n",
      "INFO: Status is pending. A Gretel Cloud worker is being allocated\n",
      "INFO: Status is active. A worker has started!\n",
      "2024-02-09T12:39:34.313771Z  Loading model to worker\n",
      "2024-02-09T12:39:53.321176Z  Sampling 5 records using conditioning input...\n",
      "2024-02-09T12:39:53.321711Z  Using device 'cuda'\n",
      "2024-02-09T12:44:06.108438Z  Generating records...\n",
      "{\n",
      "    \"num_records\": 5\n",
      "}\n",
      "2024-02-09T12:44:09.367384Z  Successfully generated 5 records\n",
      "2024-02-09T12:44:09.398939Z  Uploading artifacts to Gretel Cloud...\n",
      "2024-02-09T12:44:09.773116Z  Upload to Gretel Cloud is completed.\n"
     ]
    }
   ],
   "source": [
    "response_handler.submit_cloud()\n",
    "poll(response_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fa1560b-d01d-440b-9d73-93623a113c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt\n",
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(response_handler.get_artifact_link(\"data\"), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6fb1d-d3f3-417d-88ae-3e966d9d0d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "434f1311-fb55-4d19-b495-8ffd41c31b5f",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "928468ec-d9bb-46ac-a0f9-85639fb2d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.24.0\n",
      "Torch version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d192014-ea8f-4dfa-ab68-9f4fac5ecae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aebb72f9-7bb0-4353-8465-38499e92e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Set the device to CUDA\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Using GPU: {torch.cuda.get_device_name()}')\n",
    "else:\n",
    "    # If CUDA is not available, fall back to CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('GPU is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8dbe509-d5c6-48f3-af0e-862bc0a612ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047158e080b74bd6bbeef36e6656d928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaviB\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\RaviB\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae5a3df38fa4666a48301a844aa4f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9315edb08144d482aad10de8044d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369f2fe696cf440bb8b0217614c50ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fe5502a-1340-4046-ac1f-a9555b7941a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df3['recipeTypeName'].tolist()\n",
    "outputs = df3['ingredientsList'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64ce51e9-6202-49d6-804c-80b24a41bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(inputs, return_tensors='pt', padding=True, truncation=True)\n",
    "train_labels = tokenizer(outputs, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d669c004-fdcf-4cab-ab8c-2caf69848482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c7b566e-95f0-4781-b530-9d96ed412d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f84791b-c64e-4eba-bd10-0a6eeb856284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  209,  3648,   508,  ...,     0,     0,     0],\n",
       "        [    3, 22954,   122,  ...,     0,     0,     0],\n",
       "        [  209,  4119,     3,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  204,     3,    17,  ...,     0,     0,     0],\n",
       "        [  220, 18396,     7,  ...,     0,     0,     0],\n",
       "        [ 1429,   204,     3,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6bad829-6c09-4dc5-ac5f-294b2943f292",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minputs, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(train_encodings['input_ids']), batch_size):\n",
    "        inputs = train_encodings['input_ids'][i:i+batch_size]\n",
    "        labels = train_labels['input_ids'][i:i+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=inputs, labels=labels)\n",
    "        loss = criterion(outputs.logits.view(-1, outputs.logits.shape[-1]), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9b654-fbb2-4bd9-896e-76bba0806bb6",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Adapting this notebook: https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb#scrollTo=dEutWnhiWRAq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47991421-a8c8-40de-881b-571d8c1a6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Tensorflow:  2.10.1\n",
      "Transformers:  4.24.0\n",
      "Datasets:  2.14.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
    "import datetime\n",
    "import os\n",
    "%load_ext tensorboard\n",
    "\n",
    "tf_version = tf.__version__\n",
    "print(\"Tensorflow: \", tf_version)\n",
    "print(\"Transformers: \", transformers.__version__)\n",
    "print(\"Datasets: \", datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "410e5645-62fb-4ed7-8fa7-355abe408323",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_version_split = tf_version.split('.')\n",
    "assert int(tf_version_split[0])==2 and int(tf_version_split[-2])>=3, f\"Tensorflow version should be '2.3+,x', given {tf_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac4945ad-6085-4329-b1a3-a6dceb747024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "\n",
    "data_dir = \"./data\"\n",
    "log_dir = f\"{data_dir}/experiments/t5/logs\"\n",
    "save_path = f\"{data_dir}/experiments/t5/models\"\n",
    "cache_path_train = f\"{data_dir}/cache/t5.train\"\n",
    "cache_path_test = f\"{data_dir}/cache/t5.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "454eda6a-8256-4254-9e1f-bb16d6b8bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapthatT5(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f0a3c54-8934-4d22-8225-264095db88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", model_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e2761bc-6555-4daf-9db3-691b03694df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df3['recipeTypeName'].tolist()\n",
    "outputs = df3['ingredientsList'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82d3f950-3a87-44b0-9fc9-38e09e477860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaviB\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tokenizer(inputs, \n",
    "                           truncation=True, \n",
    "                           return_tensors='tf', \n",
    "                           max_length=1024,\n",
    "                           pad_to_max_length=True)\n",
    "\n",
    "decoder_inputs = tokenizer(outputs, \n",
    "                           truncation=True, \n",
    "                           return_tensors='tf', \n",
    "                           max_length=1024,\n",
    "                           pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc3015ec-9686-4043-a0db-70036fc36f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoder_inputs['input_ids'][0]\n",
    "input_attention = encoder_inputs['attention_mask'][0]\n",
    "target_ids = decoder_inputs['input_ids'][0]\n",
    "target_attention = decoder_inputs['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5c81671-915a-45fc-8af5-351c4652f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "           'labels':target_ids, 'decoder_attention_mask':target_attention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f26092a5-29d0-4f88-b08d-05fa58e9072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([3901, 2782, 6855, ...,    0,    0,    0])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([1, 1, 1, ..., 0, 0, 0])>,\n",
       " 'labels': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([ 209, 3648,  508, ...,    0,    0,    0])>,\n",
       " 'decoder_attention_mask': <tf.Tensor: shape=(1024,), dtype=int32, numpy=array([1, 1, 1, ..., 0, 0, 0])>}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = outputs\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e051bb1-13e6-4fbe-8d1a-2ddff6e8cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from the mapped dataset:\n",
      " tf.Tensor(3901, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ex = next(iter(train_ds['input_ids']))\n",
    "print(\"Example data from the mapped dataset:\\n\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2abaaf9f-7e08-475c-ba96-60d7bc711c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_dataset(dataset):  \n",
    "  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "  dataset.set_format(type='tensorflow', columns=columns)\n",
    "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n",
    "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\n",
    "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n",
    "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\n",
    "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8ecf9175-76ef-4b29-88c7-15b34129ac24",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'set_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mto_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[104], line 3\u001b[0m, in \u001b[0;36mto_tf_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_tf_dataset\u001b[39m(dataset):  \n\u001b[0;32m      2\u001b[0m   columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m   \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m      4\u001b[0m   return_types \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:tf\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m:tf\u001b[38;5;241m.\u001b[39mint32, \n\u001b[0;32m      5\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m:tf\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m:tf\u001b[38;5;241m.\u001b[39mint32,  }\n\u001b[0;32m      6\u001b[0m   return_shapes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39mTensorShape([\u001b[38;5;28;01mNone\u001b[39;00m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39mTensorShape([\u001b[38;5;28;01mNone\u001b[39;00m]), \n\u001b[0;32m      7\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39mTensorShape([\u001b[38;5;28;01mNone\u001b[39;00m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m:tf\u001b[38;5;241m.\u001b[39mTensorShape([\u001b[38;5;28;01mNone\u001b[39;00m])}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'set_format'"
     ]
    }
   ],
   "source": [
    "to_tf_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17cf3c-cb6a-4570-bc06-8c39949259e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
