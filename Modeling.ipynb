{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f959da6a-8b95-4246-b31f-e6de97aa57de",
   "metadata": {},
   "source": [
    "# Building a Vegan Likelihood Model\n",
    "\n",
    "The goal is to build a model to either predict if a dish is vegan just from the recipe name, or create a scoring model to predict how likely or easily a recipe is or could be vegan.\n",
    "\n",
    "Or rather, we can take the cosine similarity with a user input for a recipe name and out list of recipes from out database, and then use the top score to get the list of ingredients. Then our model can predict how likely the recipe would be vegan. Could just also list out potentially ingredients that would likely show up as non-vegan in this recipe to watch out for.\n",
    "\n",
    "## EDA and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edb738a-2166-4cd7-8b6d-5631c30f035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c42503f-16cb-49ce-b3c3-2515826ad577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('example_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b720add-c477-4217-8d9d-97e5110cf0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uri', 'label', 'image', 'source', 'url', 'shareAs', 'yield',\n",
       "       'dietLabels', 'healthLabels', 'cautions', 'ingredientLines',\n",
       "       'ingredients', 'calories', 'totalWeight', 'totalTime', 'cuisineType',\n",
       "       'mealType', 'dishType', 'totalNutrients', 'totalDaily', 'digest',\n",
       "       'tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefd959d-c5dc-4709-943f-0e53cbb038f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_col = df['ingredients'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b043d24c-6050-4f02-8fb2-3f4e64fb081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '375g/13oz plain flour',\n",
       " 'quantity': 375.0,\n",
       " 'measure': 'gram',\n",
       " 'food': 'flour',\n",
       " 'weight': 375.0,\n",
       " 'foodCategory': 'grains',\n",
       " 'foodId': 'food_ahebfs0a985an4aubqaebbipra58',\n",
       " 'image': 'https://www.edamam.com/food-img/b4c/b4c739e76a6f2172b7ad49d0aa41d5aa.jpg'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_col[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78756df-82f6-4fe2-8067-f931b312e4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = dict()\n",
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44482a36-b494-4773-8084-78836899cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredients_col[1][0]['foodCategory']\n",
    "dct[ingredients_col[1][0]['foodCategory']] = ingredients_col[1][0]['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c034e23b-b270-411b-91ab-cc0455e59d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = dict()\n",
    "for i, row in ingredients_col.items():\n",
    "    for j in range(len(row)):\n",
    "        key = row[j]['foodCategory']\n",
    "        value = row[j]['quantity']\n",
    "\n",
    "        if key in dct.keys():\n",
    "            dct[key] += value\n",
    "        else:\n",
    "            dct[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9fc5a72-a771-40f2-a02f-364f20122004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'text' in ingredients_col[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad943c9-378f-42b0-9689-76d03095326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Eggs', 'Milk', 'Cheese', 'Dairy', 'grains', 'Condiments and sauces', 'condiments and sauces', 'Oils', 'vegetables', 'canned vegetables', 'milk', 'bread, rolls and tortillas', 'cured meats', 'fruit', 'canned grains', 'canned soup', 'bov', 'plant-based protein', 'sugars', 'quick breads and pastries', 'wines', '100% juice', 'water', 'yogurt', 'beer', 'ready-to-eat cereals', 'sugar syrups', 'Cured meats', 'crackers', 'savory snacks', 'liquors and cocktails', 'meats', 'sugar jam', 'Vegan products', 'candy', 'chocolate', None, 'canned fruit', 'non-dairy beverages', 'flavored water', 'cocktails and liquors', 'canned seafood', 'seafood', 'Poultry', 'sweetened beverages', 'pastries', 'frozen treats', 'coffee and tea', 'eggs', 'cooked grains', 'Plant-based protein', 'frozen grained based', 'mixed grains', 'sandwhiches', 'protein and nutritional powders', 'salads'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c26829e-9dd6-4c08-bd3d-2937eface087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil, '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_s = ''\n",
    "ex_s_lst = ast.literal_eval(df.iloc[0]['ingredientLines'])\n",
    "for s in ex_s_lst:\n",
    "    ex_s += s + ', '\n",
    "\n",
    "ex_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3a37ec-a80a-4275-9465-7c2ca754aa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(ex_s_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc99227-97c1-4425-89ab-e835457f358f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b177d98-79f5-469b-b69a-1b7d09974a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a2f5e2-44d1-4bc5-8c18-1d45acf3b535",
   "metadata": {},
   "source": [
    "## Preprocessing for Transformer\n",
    "\n",
    "Going to try to preprocess data to take the dish/recipe name (`label` column) and the `healthLabel` as input, and output the ingredients list as a long string. We can use a transformer for this to output the recipe's ingredients in long text form. \n",
    "\n",
    "The `healthLabel` will only be a select few options though, and the user can only select 1 for now, from: ['Mediterranean', 'Vegetarian', 'Vegan', 'Red-Meat-Free', 'Paleo', 'Pescatarian']. When reducing the healthLabels column from multilabel to categorical, we need to define a priority order, and if none of these are there then the dish is balanced, so we will add that as an option. In the future, some analysis on this column should be done to improve the priority order, rather than relying on domain knowledge. Alternatively, and option to select multiple could be implemented instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9c6f09a-f93f-4da7-8221-749d8bbafb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_order = ['Vegan', 'Vegetarian', 'Pescatarian', 'Paleo', 'Red-Meat-Free', 'Mediterranean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58cce8a8-8151-4c94-aafd-227a9a869137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "1       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "2       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "3       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "4       [Vegetarian, Pescatarian, Egg-Free, Peanut-Fre...\n",
       "                              ...                        \n",
       "1195    [Keto-Friendly, Pescatarian, Mediterranean, Gl...\n",
       "1196    [Pescatarian, Gluten-Free, Wheat-Free, Egg-Fre...\n",
       "1197    [Sugar-Conscious, Keto-Friendly, Pescatarian, ...\n",
       "1198    [Sugar-Conscious, Keto-Friendly, Pescatarian, ...\n",
       "1199    [Sugar-Conscious, Pescatarian, Mediterranean, ...\n",
       "Name: healthLabels, Length: 1200, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_labels = df['healthLabels'].apply(ast.literal_eval)\n",
    "health_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e874203-9b73-452c-8ca8-3486f89194a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_priority(labels):\n",
    "    for label in priority_order:\n",
    "        if label in labels:\n",
    "            return label\n",
    "    return 'Balanced'  # Handle case where no label matches priority_order, in which case the diet is balanced\n",
    "\n",
    "# Apply function to the multilabels series\n",
    "diet_type = health_labels.apply(replace_with_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa78ee3-5e60-4ac1-bccb-18652857abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "healthLabels\n",
       "Vegetarian       400\n",
       "Vegan            279\n",
       "Pescatarian      209\n",
       "Balanced         181\n",
       "Red-Meat-Free     57\n",
       "Paleo             42\n",
       "Mediterranean     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068e884-2b21-45a4-98b9-7273114f9141",
   "metadata": {},
   "source": [
    "Now we have our dietary preference column. The recipe name is fine as is so next is the ingredients list which is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cea2701-1126-46b3-b274-b649de8b9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_name = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec883fa-1abb-43b8-bec6-e58d3b694e2e",
   "metadata": {},
   "source": [
    "We need to just join these lists of strings with commas so they be user friendly to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63f43efe-cf87-4441-a004-7bc40cf2401a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1 organic large egg, 1 teaspoon whole milk or ...\n",
       "1       375g/13oz plain flour, Pinch salt, 225g/8oz bu...\n",
       "2       1 cup asiago cheese, grated, 1 cup fontina che...\n",
       "3       4 ounces, weight Cream Cheese, Softened, 1/2 c...\n",
       "4       8 ounces elbow pasta, 1/4 cup unsalted butter,...\n",
       "                              ...                        \n",
       "1195    4 (6 ounce) tilapia fillets, salt, pepper, 1/2...\n",
       "1196    * 1 Vegetable oil cooking spray, * 4 U.S.-farm...\n",
       "1197    2 tbsp chopped red onion, 1 tbsp olive oil, 1 ...\n",
       "1198    3 tablespoons unsalted butter, 2 tablespoons e...\n",
       "1199    * 2 tilapia fillets (skinless, about 4 ounces ...\n",
       "Name: ingredientLines, Length: 1200, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_lst = df['ingredientLines'].apply(ast.literal_eval)\n",
    "ingredients_lst = ingredients_lst.apply(lambda x: ', '.join(x))\n",
    "ingredients_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83e4d7-0b6d-4067-80db-90a4beb405dc",
   "metadata": {},
   "source": [
    "Now we can make our dataframe for the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d95c300-2ddf-405b-bdc3-6202a792e31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dietType</th>\n",
       "      <th>recipeName</th>\n",
       "      <th>ingredientsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Cheese Omelette</td>\n",
       "      <td>1 organic large egg, 1 teaspoon whole milk or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Cheese straws</td>\n",
       "      <td>375g/13oz plain flour, Pinch salt, 225g/8oz bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>CHEESE GOOP</td>\n",
       "      <td>1 cup asiago cheese, grated, 1 cup fontina che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Pimento Cheese</td>\n",
       "      <td>4 ounces, weight Cream Cheese, Softened, 1/2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Five Cheese Skillet Mac and Cheese recipes</td>\n",
       "      <td>8 ounces elbow pasta, 1/4 cup unsalted butter,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dietType                                  recipeName  \\\n",
       "0  Vegetarian                             Cheese Omelette   \n",
       "1  Vegetarian                               Cheese straws   \n",
       "2  Vegetarian                                 CHEESE GOOP   \n",
       "3  Vegetarian                              Pimento Cheese   \n",
       "4  Vegetarian  Five Cheese Skillet Mac and Cheese recipes   \n",
       "\n",
       "                                     ingredientsList  \n",
       "0  1 organic large egg, 1 teaspoon whole milk or ...  \n",
       "1  375g/13oz plain flour, Pinch salt, 225g/8oz bu...  \n",
       "2  1 cup asiago cheese, grated, 1 cup fontina che...  \n",
       "3  4 ounces, weight Cream Cheese, Softened, 1/2 c...  \n",
       "4  8 ounces elbow pasta, 1/4 cup unsalted butter,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([diet_type, recipe_name, ingredients_lst], axis = 1)\n",
    "column_names = {'healthLabels': 'dietType', 'label': 'recipeName', 'ingredientLines': 'ingredientsList'}\n",
    "df2 = df2.rename(columns=column_names)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7294644-425f-4820-81cd-66c08a96de3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipeTypeName</th>\n",
       "      <th>ingredientsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegetarian Cheese Omelette</td>\n",
       "      <td>1 organic large egg, 1 teaspoon whole milk or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegetarian Cheese straws</td>\n",
       "      <td>375g/13oz plain flour, Pinch salt, 225g/8oz bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian CHEESE GOOP</td>\n",
       "      <td>1 cup asiago cheese, grated, 1 cup fontina che...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               recipeTypeName  \\\n",
       "0  Vegetarian Cheese Omelette   \n",
       "1    Vegetarian Cheese straws   \n",
       "2      Vegetarian CHEESE GOOP   \n",
       "\n",
       "                                     ingredientsList  \n",
       "0  1 organic large egg, 1 teaspoon whole milk or ...  \n",
       "1  375g/13oz plain flour, Pinch salt, 225g/8oz bu...  \n",
       "2  1 cup asiago cheese, grated, 1 cup fontina che...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models (transformers) can't handle tabular data well so we concatenate input columns\n",
    "df3 = pd.concat([df2['dietType'] + ' ' + df2['recipeName'], df2['ingredientsList']], axis = 1)\n",
    "df3 = df3.rename(columns={0: 'recipeTypeName'})\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc7fdf7-7b80-4049-8a1d-11f7e2cd6489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3.to_csv('preprocessed_example_recipes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce3170-0a84-48b4-bf52-70340f609b74",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa471d8-e24d-41a3-ad6b-65c7d7c3f79c",
   "metadata": {},
   "source": [
    "### Gretel\n",
    "\n",
    "https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/conditional_text_generation_with_gpt.ipynb#scrollTo=YMg9nX6SczHe\n",
    "\n",
    "https://gretel.ai/blog/conditional-text-generation-by-fine-tuning-gretel-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08200302-9632-4b54-9c5c-ae98bc23aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client import configure_session\n",
    "from gretel_client.helpers import poll\n",
    "from gretel_client.projects import create_or_get_unique_project, get_project\n",
    "from gretel_client.projects.models import read_model_config, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f4f5e00-af03-4f5f-8492-c3f0f3c2e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = \"gretelai/mpt-7b\"  # @param {type:\"string\"}\n",
    "GRETEL_PROJECT = 'edamam'  # @param {type:\"string\"}\n",
    "TEXT_COLUMN = \"text\"# @param {type:\"string\"}\n",
    "LABEL_COLUMN = \"ingredientsList\" # @param {type:\"string\"}\n",
    "LABEL_AND_TEXT_COLUMN = 'recipeTypeName'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1dc0fe5-65be-4826-80d4-d7081bf54754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schema_version': '1.0',\n",
       " 'name': 'natural-language-gpt',\n",
       " 'models': [{'gpt_x': {'data_source': '__temp__',\n",
       "    'pretrained_model': 'gretelai/mpt-7b',\n",
       "    'column_name': 'recipeTypeName',\n",
       "    'params': {'batch_size': 4,\n",
       "     'steps': 750,\n",
       "     'weight_decay': 0.01,\n",
       "     'warmup_steps': 100,\n",
       "     'lr_scheduler': 'linear',\n",
       "     'learning_rate': 0.0002},\n",
       "    'generate': {'num_records': 80, 'maximum_text_length': 100}}}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = read_model_config(\"synthetics/natural-language\")\n",
    "config['models'][0]['gpt_x']['pretrained_model'] = LLM\n",
    "config['models'][0]['gpt_x']['column_name'] = LABEL_AND_TEXT_COLUMN\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2da52d18-f906-463b-9920-5f51afd53491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Gretel Api Key ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config file C:\\Users\\RaviB\\.gretel\\config.json is group- and/or world-readable!\n",
      "Setting permissions to be readable by the owner only.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching Gretel config to disk.\n",
      "Using endpoint https://api.gretel.cloud\n",
      "Logged in as ravinderbrai@gmail.com ✅\n"
     ]
    }
   ],
   "source": [
    "configure_session(api_key=\"prompt\", cache=\"yes\", endpoint=\"https://api.gretel.cloud\", validate=True, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41fab7a3-c9e2-4147-bf8f-d59a6e02785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = create_or_get_unique_project(name=GRETEL_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21043479-bddc-4fc1-a38e-ba356e5c6d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow along with training in the console: https://console.gretel.ai/proj_2c86dkC0SVcsijB19WyuyyBDU9L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting poller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"uid\": \"65c618ccfdff8e43a5ba293a\",\n",
      "    \"guid\": \"model_2c87L94yO3kjdN97XnZcn7bSkK2\",\n",
      "    \"model_name\": \"edamam-gretelai/mpt-7b\",\n",
      "    \"model_key\": \"\",\n",
      "    \"runner_mode\": \"cloud\",\n",
      "    \"user_id\": \"65c58885ece628960a93314c\",\n",
      "    \"user_guid\": \"user_2c6uTY9yUSoUHG8IgV8qYGvL9F6\",\n",
      "    \"billing_domain\": null,\n",
      "    \"billing_domain_guid\": null,\n",
      "    \"project_id\": \"65c61773c22c3df5e1726865\",\n",
      "    \"project_guid\": \"proj_2c86dkC0SVcsijB19WyuyyBDU9L\",\n",
      "    \"cluster_guid\": null,\n",
      "    \"status_history\": {\n",
      "        \"created\": \"2024-02-09T12:21:32.831198Z\"\n",
      "    },\n",
      "    \"last_modified\": \"2024-02-09T12:21:32.897097Z\",\n",
      "    \"status\": \"created\",\n",
      "    \"last_active_hb\": null,\n",
      "    \"duration_minutes\": null,\n",
      "    \"error_msg\": null,\n",
      "    \"error_id\": null,\n",
      "    \"traceback\": null,\n",
      "    \"annotations\": null,\n",
      "    \"provenance\": null,\n",
      "    \"container_image\": \"074762682575.dkr.ecr.us-west-2.amazonaws.com/models/gpt_x@sha256:893f53dfe4f500e1f64bf1064c5370a3da5886f70db184bafa300461b8f59820\",\n",
      "    \"container_image_version\": \"2.10.108\",\n",
      "    \"model_type\": \"gpt_x\",\n",
      "    \"model_type_alias\": null,\n",
      "    \"project_name\": \"edamam\",\n",
      "    \"config\": {\n",
      "        \"schema_version\": \"1.0\",\n",
      "        \"name\": \"edamam-gretelai/mpt-7b\",\n",
      "        \"models\": [\n",
      "            {\n",
      "                \"gpt_x\": {\n",
      "                    \"data_source\": [\n",
      "                        \"gretel_973d27d0b3e6466ba31ad588f4703401_dataframe-864babbe-7a05-4e33-b64d-f63a17ca7e96.csv\"\n",
      "                    ],\n",
      "                    \"ref_data\": {},\n",
      "                    \"pretrained_model\": \"gretelai/mpt-7b\",\n",
      "                    \"prompt_template\": null,\n",
      "                    \"column_name\": \"recipeTypeName\",\n",
      "                    \"validation\": null,\n",
      "                    \"params\": {\n",
      "                        \"batch_size\": 4,\n",
      "                        \"epochs\": null,\n",
      "                        \"steps\": 750,\n",
      "                        \"weight_decay\": 0.01,\n",
      "                        \"warmup_steps\": 100,\n",
      "                        \"lr_scheduler\": \"linear\",\n",
      "                        \"learning_rate\": 0.0002,\n",
      "                        \"max_tokens\": 512\n",
      "                    },\n",
      "                    \"generate\": {\n",
      "                        \"num_records\": 80,\n",
      "                        \"seed_records_multiplier\": 1,\n",
      "                        \"maximum_text_length\": 100,\n",
      "                        \"top_p\": 0.8987601335810778,\n",
      "                        \"top_k\": 43,\n",
      "                        \"num_beams\": 1,\n",
      "                        \"do_sample\": true,\n",
      "                        \"do_early_stopping\": true,\n",
      "                        \"typical_p\": 0.8,\n",
      "                        \"temperature\": null\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"notifications\": null,\n",
      "        \"label_predictors\": null\n",
      "    },\n",
      "    \"autouse_config\": null,\n",
      "    \"autouse_handler_id\": null,\n",
      "    \"auth_source\": \"grtu\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Status is created. Model creation has been queued.\n",
      "INFO: Status is pending. A Gretel Cloud worker is being allocated to begin model creation.\n",
      "INFO: Status is active. A worker has started creating your model!\n",
      "2024-02-09T12:21:54.400419Z  Resolved revision for model\n",
      "{\n",
      "    \"revision\": \"4a89ac4fb5c17e714cc27967728b2edd0a401516\",\n",
      "    \"model\": \"gretelai/mpt-7b\"\n",
      "}\n",
      "2024-02-09T12:21:54.400972Z  Parameter efficient fine tuning (PEFT) methods will be used, which greatly reduce the number of trainable parameters.\n",
      "2024-02-09T12:21:54.404917Z  Starting GPT model training...\n",
      "{\n",
      "    \"num_train_steps\": 750\n",
      "}\n",
      "2024-02-09T12:21:54.405266Z  Fine-tuning 'gretelai/mpt-7b' with provided dataset!\n",
      "2024-02-09T12:21:54.405503Z  Disclaimer: the chosen model may produce untrue and/or offensive content without warning. For more info, see https://docs.gretel.ai/reference/synthetics/models/gretel-gpt#limitations-and-biases\n",
      "2024-02-09T12:21:54.405849Z  Downloading model from remote source. Depending on the size of the model, this may take a few minutes.\n",
      "2024-02-09T12:22:54.406381Z  Model download 73% complete, ETA 23s (9643812960/13300902259 bytes downloaded)\n",
      "2024-02-09T12:23:23.188320Z  Model download 100% complete (13300902259 bytes downloaded). Loading model onto GPU ...\n",
      "2024-02-09T12:23:54.411582Z  Still loading model ...\n",
      "2024-02-09T12:24:54.420751Z  Still loading model ...\n",
      "2024-02-09T12:25:54.421524Z  Still loading model ...\n",
      "2024-02-09T12:26:08.910884Z  Successfully loaded model and tokenizer.\n",
      "2024-02-09T12:26:08.913131Z  PEFT trainable params: 4194304 || all params: 6653480960 || trainable%: 0.0630392425441013\n",
      "2024-02-09T12:27:11.367536Z  Training in progress, 16.0% complete (step 120/750, ETA 324s)\n",
      "{\n",
      "    \"loss\": 4.3908,\n",
      "    \"learning_rate\": 3e-05,\n",
      "    \"epoch\": 0.4,\n",
      "    \"step\": 120\n",
      "}\n",
      "2024-02-09T12:28:13.938029Z  Training in progress, 33.1% complete (step 248/750, ETA 251s)\n",
      "{\n",
      "    \"loss\": 3.6744,\n",
      "    \"learning_rate\": 6.2e-05,\n",
      "    \"epoch\": 0.83,\n",
      "    \"step\": 248\n",
      "}\n",
      "2024-02-09T12:28:39.301273Z  Training in progress, 39.5% complete (step 296/750, ETA 229s)\n",
      "{\n",
      "    \"loss\": 3.2509,\n",
      "    \"learning_rate\": 7.4e-05,\n",
      "    \"epoch\": 0.99,\n",
      "    \"step\": 296\n",
      "}\n",
      "2024-02-09T12:29:43.644159Z  Training in progress, 57.6% complete (step 432/750, ETA 157s)\n",
      "{\n",
      "    \"loss\": 2.4238,\n",
      "    \"learning_rate\": 0.00010800000000000001,\n",
      "    \"epoch\": 1.44,\n",
      "    \"step\": 432\n",
      "}\n",
      "2024-02-09T12:30:46.006006Z  Training in progress, 74.7% complete (step 560/750, ETA 94s)\n",
      "{\n",
      "    \"loss\": 2.0013,\n",
      "    \"learning_rate\": 0.000138,\n",
      "    \"epoch\": 1.87,\n",
      "    \"step\": 560\n",
      "}\n",
      "2024-02-09T12:31:05.506610Z  Training in progress, 80.0% complete (step 600/750, ETA 74s)\n",
      "{\n",
      "    \"loss\": 1.8356,\n",
      "    \"learning_rate\": 0.000148,\n",
      "    \"epoch\": 2.0,\n",
      "    \"step\": 600\n",
      "}\n",
      "2024-02-09T12:32:08.007262Z  Training in progress, 97.1% complete (step 728/750, ETA 11s)\n",
      "{\n",
      "    \"loss\": 1.7706,\n",
      "    \"learning_rate\": 0.00018,\n",
      "    \"epoch\": 2.43,\n",
      "    \"step\": 728\n",
      "}\n",
      "2024-02-09T12:32:19.695407Z  Training in progress, 100.0% complete (step 750/750, ETA 0s)\n",
      "{\n",
      "    \"loss\": 1.8153,\n",
      "    \"learning_rate\": 0.00018600000000000002,\n",
      "    \"epoch\": 2.51,\n",
      "    \"step\": 750\n",
      "}\n",
      "2024-02-09T12:32:19.695991Z  Training in progress, 100.0% complete (step 750/750, ETA 0s)\n",
      "{\n",
      "    \"train_runtime\": 369.9767,\n",
      "    \"train_samples_per_second\": 8.13,\n",
      "    \"train_steps_per_second\": 0.254,\n",
      "    \"train_loss\": 2.7695447231860872,\n",
      "    \"epoch\": 2.51,\n",
      "    \"step\": 750\n",
      "}\n",
      "2024-02-09T12:32:19.696843Z  Training is completed!\n",
      "2024-02-09T12:32:19.697275Z  GPT model training complete.\n",
      "2024-02-09T12:32:19.697731Z  Saving model\n",
      "2024-02-09T12:32:19.742514Z  Sampling 80 records using auto prompting.\n",
      "2024-02-09T12:32:19.744141Z  Using device 'cuda'\n",
      "2024-02-09T12:32:19.915207Z  Generating records...\n",
      "{\n",
      "    \"num_records\": 80\n",
      "}\n",
      "2024-02-09T12:32:29.071456Z  Successfully generated 80 records\n",
      "2024-02-09T12:32:29.081486Z  Creating Synthetic Text Data Quality Report...\n",
      "2024-02-09T12:32:29.081818Z  Creating text metrics report...\n",
      "2024-02-09T12:32:39.853649Z  Finished creating text metrics report.\n",
      "2024-02-09T12:32:39.869477Z  Synthetic Text Data Quality Report finished, exporting report artifacts...\n",
      "2024-02-09T12:32:39.870591Z  Model has been created successfully\n",
      "2024-02-09T12:32:42.079676Z  Uploading artifacts to Gretel Cloud...\n",
      "2024-02-09T12:32:43.392112Z  Upload to Gretel Cloud is completed.\n"
     ]
    }
   ],
   "source": [
    "model = project.create_model_obj(model_config=config, data_source=df3)\n",
    "print(f\"Follow along with training in the console: {project.get_console_url()}\")\n",
    "model.name = f\"{GRETEL_PROJECT}-{LLM}\"\n",
    "model.submit_cloud()\n",
    "\n",
    "poll(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "706ba397-8bf1-4111-8b8a-e9c97788862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LABEL = \"Vegan Carrot Juice\"  # @param {type:\"string\"}\n",
    "NUM_RECORDS = 5  # @param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cf2647c-3787-43a0-b222-5346b3bd7425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text completion prompts with class labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegan Carrot Juice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               prompt\n",
       "0  Vegan Carrot Juice\n",
       "1  Vegan Carrot Juice\n",
       "2  Vegan Carrot Juice\n",
       "3  Vegan Carrot Juice\n",
       "4  Vegan Carrot Juice"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_prompt_df(prompt_label: str, num_records: int = 25) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a prompt DataFrame with the given number of rows, each containing a prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt_label (str): The class label to use in the prompt.\n",
    "        num_records (int): The number of records to generate in the prompt DataFrame.\n",
    "            The generated synthetic data will have the same number of records.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the given number of rows, each containing a class\n",
    "            label prompt.\n",
    "    \"\"\"\n",
    "    # Note: the column name in this dataframe doesn't matter, as it may only contain a single\n",
    "    # column anyway.\n",
    "    # The column name in the generated synthetic data will be taken from the training dataset\n",
    "    # instead.\n",
    "    return pd.DataFrame([prompt_label] * num_records, columns=[\"prompt\"])\n",
    "\n",
    "\n",
    "print(\"Text completion prompts with class labels\")\n",
    "prompt_df = create_prompt_df(PROMPT_LABEL, num_records=NUM_RECORDS)\n",
    "prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67d445e3-5977-400d-b211-32f28f53a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_handler = model.create_record_handler_obj(\n",
    "        params={\"maximum_text_length\": 100, \"temperature\": 0.7},\n",
    "        data_source=prompt_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ef6dc19-dda7-4986-ab93-aeaa1f3e9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting poller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"uid\": \"65c61cf766d154ace237a255\",\n",
      "    \"guid\": \"model_run_2c89VDPpveIi7YZFnV4GWbdlH5q\",\n",
      "    \"model_name\": null,\n",
      "    \"model_key\": \"\",\n",
      "    \"runner_mode\": \"cloud\",\n",
      "    \"user_id\": \"65c58885ece628960a93314c\",\n",
      "    \"user_guid\": \"user_2c6uTY9yUSoUHG8IgV8qYGvL9F6\",\n",
      "    \"billing_domain\": null,\n",
      "    \"billing_domain_guid\": null,\n",
      "    \"project_id\": \"65c61773c22c3df5e1726865\",\n",
      "    \"project_guid\": \"proj_2c86dkC0SVcsijB19WyuyyBDU9L\",\n",
      "    \"cluster_guid\": null,\n",
      "    \"status_history\": {\n",
      "        \"created\": \"2024-02-09T12:39:19.717000Z\"\n",
      "    },\n",
      "    \"last_modified\": \"2024-02-09T12:39:19.861000Z\",\n",
      "    \"status\": \"created\",\n",
      "    \"last_active_hb\": null,\n",
      "    \"duration_minutes\": null,\n",
      "    \"error_msg\": null,\n",
      "    \"error_id\": null,\n",
      "    \"traceback\": null,\n",
      "    \"annotations\": null,\n",
      "    \"provenance\": null,\n",
      "    \"container_image\": \"074762682575.dkr.ecr.us-west-2.amazonaws.com/models/gpt_x@sha256:893f53dfe4f500e1f64bf1064c5370a3da5886f70db184bafa300461b8f59820\",\n",
      "    \"container_image_version\": \"2.10.108\",\n",
      "    \"model_id\": \"65c618ccfdff8e43a5ba293a\",\n",
      "    \"model_guid\": \"model_2c87L94yO3kjdN97XnZcn7bSkK2\",\n",
      "    \"model_type\": \"gpt_x\",\n",
      "    \"action\": \"gpt_x_run\",\n",
      "    \"config\": {\n",
      "        \"data_source\": \"gretel_2edf976b56e143ec8407496d79710f73_dataframe-086fc73b-a166-4dca-b694-bb85c6b0e576.csv\",\n",
      "        \"ref_data\": {},\n",
      "        \"params\": {\n",
      "            \"num_records\": null,\n",
      "            \"seed_records_multiplier\": 1,\n",
      "            \"maximum_text_length\": 100,\n",
      "            \"top_p\": 0.8987601335810778,\n",
      "            \"top_k\": 43,\n",
      "            \"num_beams\": 1,\n",
      "            \"do_sample\": true,\n",
      "            \"do_early_stopping\": true,\n",
      "            \"typical_p\": 0.8,\n",
      "            \"temperature\": 0.7,\n",
      "            \"num_records_multiplier\": null,\n",
      "            \"prompt\": null\n",
      "        }\n",
      "    },\n",
      "    \"is_autouse\": false,\n",
      "    \"auth_source\": \"grtu\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Status is created. A job has been queued.\n",
      "INFO: Status is pending. A Gretel Cloud worker is being allocated\n",
      "INFO: Status is active. A worker has started!\n",
      "2024-02-09T12:39:34.313771Z  Loading model to worker\n",
      "2024-02-09T12:39:53.321176Z  Sampling 5 records using conditioning input...\n",
      "2024-02-09T12:39:53.321711Z  Using device 'cuda'\n",
      "2024-02-09T12:44:06.108438Z  Generating records...\n",
      "{\n",
      "    \"num_records\": 5\n",
      "}\n",
      "2024-02-09T12:44:09.367384Z  Successfully generated 5 records\n",
      "2024-02-09T12:44:09.398939Z  Uploading artifacts to Gretel Cloud...\n",
      "2024-02-09T12:44:09.773116Z  Upload to Gretel Cloud is completed.\n"
     ]
    }
   ],
   "source": [
    "response_handler.submit_cloud()\n",
    "poll(response_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fa1560b-d01d-440b-9d73-93623a113c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt\n",
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(response_handler.get_artifact_link(\"data\"), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6fb1d-d3f3-417d-88ae-3e966d9d0d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "434f1311-fb55-4d19-b495-8ffd41c31b5f",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "928468ec-d9bb-46ac-a0f9-85639fb2d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.24.0\n",
      "Torch version: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d192014-ea8f-4dfa-ab68-9f4fac5ecae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aebb72f9-7bb0-4353-8465-38499e92e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Set the device to CUDA\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Using GPU: {torch.cuda.get_device_name()}')\n",
    "else:\n",
    "    # If CUDA is not available, fall back to CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('GPU is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8dbe509-d5c6-48f3-af0e-862bc0a612ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047158e080b74bd6bbeef36e6656d928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaviB\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\RaviB\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae5a3df38fa4666a48301a844aa4f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9315edb08144d482aad10de8044d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369f2fe696cf440bb8b0217614c50ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fe5502a-1340-4046-ac1f-a9555b7941a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df3['recipeTypeName'].tolist()\n",
    "outputs = df3['ingredientsList'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64ce51e9-6202-49d6-804c-80b24a41bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(inputs, return_tensors='pt', padding=True, truncation=True)\n",
    "train_labels = tokenizer(outputs, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d669c004-fdcf-4cab-ab8c-2caf69848482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c7b566e-95f0-4781-b530-9d96ed412d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f84791b-c64e-4eba-bd10-0a6eeb856284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  209,  3648,   508,  ...,     0,     0,     0],\n",
       "        [    3, 22954,   122,  ...,     0,     0,     0],\n",
       "        [  209,  4119,     3,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  204,     3,    17,  ...,     0,     0,     0],\n",
       "        [  220, 18396,     7,  ...,     0,     0,     0],\n",
       "        [ 1429,   204,     3,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6bad829-6c09-4dc5-ac5f-294b2943f292",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minputs, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(train_encodings['input_ids']), batch_size):\n",
    "        inputs = train_encodings['input_ids'][i:i+batch_size]\n",
    "        labels = train_labels['input_ids'][i:i+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=inputs, labels=labels)\n",
    "        loss = criterion(outputs.logits.view(-1, outputs.logits.shape[-1]), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9b654-fbb2-4bd9-896e-76bba0806bb6",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Adapting this notebook: https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb#scrollTo=dEutWnhiWRAq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47991421-a8c8-40de-881b-571d8c1a6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Tensorflow:  2.13.1\n",
      "Transformers:  4.34.1\n",
      "Datasets:  2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
    "import datetime\n",
    "import os\n",
    "%load_ext tensorboard\n",
    "\n",
    "tf_version = tf.__version__\n",
    "print(\"Tensorflow: \", tf_version)\n",
    "print(\"Transformers: \", transformers.__version__)\n",
    "print(\"Datasets: \", datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "410e5645-62fb-4ed7-8fa7-355abe408323",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_version_split = tf_version.split('.')\n",
    "assert int(tf_version_split[0])==2 and int(tf_version_split[-2])>=3, f\"Tensorflow version should be '2.3+,x', given {tf_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac4945ad-6085-4329-b1a3-a6dceb747024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "\n",
    "data_dir = \"./data\"\n",
    "log_dir = f\"{data_dir}/experiments/t5/logs\"\n",
    "save_path = f\"{data_dir}/experiments/t5/models\"\n",
    "cache_path_train = f\"{data_dir}/cache/t5.train\"\n",
    "cache_path_test = f\"{data_dir}/cache/t5.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "454eda6a-8256-4254-9e1f-bb16d6b8bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps:  270\n",
      "Total Validation Steps:  30\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = 1e4\n",
    "batch_size = 4\n",
    "encoder_max_len = 250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000\n",
    "ntrain = len(train_dataset)\n",
    "nvalid = len(valid_dataset)\n",
    "steps = int(np.ceil(ntrain/batch_size))\n",
    "valid_steps = int(np.ceil(nvalid/batch_size))\n",
    "print(\"Total Steps: \", steps)\n",
    "print(\"Total Validation Steps: \", valid_steps)\n",
    "\n",
    "class SnapthatT5(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f0a3c54-8934-4d22-8225-264095db88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", model_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cefcda1-0c1b-47d1-9dc2-69ae70108eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8980e1299a462c9a77964ae041a570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d423b655634256a160bfbd2af382c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70689411a91443208e504c24f11c4b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e0d6bc2-d6ac-427c-bce8-dee32ef0640a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split=\"train\")\n",
    "#valid_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d3a8cf8-7e46-45bf-9bf2-34ee9e4375b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split=\"train[:90%]\")\n",
    "valid_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split='train[90%:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0bf69c3-f4f2-4320-b495-c06c0eae98d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipeTypeName': Value(dtype='string', id=None),\n",
       " 'ingredientsList': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "906df046-e780-4966-a59e-328588a4edc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from the dataset: \n",
      " {'recipeTypeName': 'Vegetarian Cheese Omelette', 'ingredientsList': '1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil'}\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataset))\n",
    "print(\"Example data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d178dc63-3fa7-4c39-9424-591aeaa74f73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saint Bernadette Soubirous'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(['Saint Bernadette Soubirous'])\n",
    "', '.join([i for i in list(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2c6eb70-052b-4b8c-90de-46f9740f9ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil']\n",
      "1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil </s>'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = list(['1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil'])\n",
    "print(s)\n",
    "s = ', '.join([i for i in list(s)])\n",
    "print(s)\n",
    "f\"{s} </s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d143fd0-326e-4849-b261-8e90686d79e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(example, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "  \n",
    "\n",
    "    recipe_type_and_name = example['recipeTypeName']\n",
    "    ingredients = example['ingredientsList']\n",
    "    \n",
    "    #context = example['context']\n",
    "    question_plus = recipe_type_and_name\n",
    "    answer = list([ingredients])\n",
    "  \n",
    "    #question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += \" </s>\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus} </s>\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                               pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                               pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention}\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2f4e164-2ba9-488c-aaa4-afa1598cfa7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaviB\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds=  train_dataset.map(encode)\n",
    "valid_ds=  valid_dataset.map(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56bbb695-f90f-4734-96fc-c55449c7fa3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from the mapped dataset: \n",
      " {'recipeTypeName': 'Vegetarian Cheese Omelette', 'ingredientsList': '1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil', 'input_ids': [3901, 2782, 6855, 21060, 13285, 15, 15529, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [209, 3648, 508, 6182, 6, 209, 21776, 829, 3702, 42, 387, 6, 209, 18396, 31984, 3285, 6, 3, 28559, 41, 4188, 54, 169, 119, 1308, 13, 3285, 201, 209, 21776, 4194, 42, 1043, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'decoder_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "ex = next(iter(train_ds))\n",
    "print(\"Example data from the mapped dataset: \\n\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e41c282-ecfa-4330-b9f2-34a6b4b0ac6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_tf_dataset(dataset):  \n",
    "  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "  dataset.set_format(type='tensorflow', columns=columns)\n",
    "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n",
    "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\n",
    "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n",
    "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\n",
    "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29822b4c-fe59-47b4-ba01-4eb43d8367d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_train_ds = to_tf_dataset(train_ds)\n",
    "tf_valid_ds = to_tf_dataset(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97a15628-30ef-47f2-82f7-2423a8cd96cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, cache_path=None, batch_size=4, \n",
    "                   buffer_size= 1000, shuffling=True):    \n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f4174e5-61e6-40aa-ae38-e17ff0ead680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                         shuffling=True, cache_path = None)\n",
    "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                         shuffling=False, cache_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb335bfa-21e6-45a1-9e35-9eb51d93a225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, warmup_steps=1e4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    m = tf.maximum(self.warmup_steps, step)\n",
    "    m = tf.cast(m, tf.float32)\n",
    "    lr = tf.math.rsqrt(m)\n",
    "    \n",
    "    return lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df237a4f-a0fb-4be2-ae2c-b64bf893428a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "schedule = CustomSchedule()\n",
    "plt.plot(schedule(tf.range(25000, dtype=tf.float32)))\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d47ed6d-7cd4-4c7b-8510-e9c3a9440617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_profile_batch = steps+10\n",
    "stop_profile_batch = start_profile_batch + 100\n",
    "profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n",
    "\n",
    "log_path = log_dir + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,\n",
    "                                                     update_freq=20,profile_batch=profile_range)\n",
    "\n",
    "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [tensorboard_callback, model_checkpoint_callback] \n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "58d5d119-7e6b-4526-9f26-cf2e00099fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#learning_rate = CustomSchedule()\n",
    "learning_rate = 0.001  # Instead set a static learning rate\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a8842a2f-c9c9-47ec-9f6e-f109368ca778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing SnapthatT5.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model SnapthatT5 were not initialized from the PyTorch model and are newly initialized: ['total', 'count']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SnapthatT5.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c30c7f6-fa3f-4aa5-9f69-00c9a2d66359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91cdc684-2ecd-4f9a-b547-ddfbc7675338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir ./data/experiments/t5/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1662d747-44c3-4947-aabd-eefd003b1638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "     74/Unknown - 378s 5s/step - accuracy: 0.6969 - loss: 2.7471 - lr: 0.0010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_valid_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_done = 0\n",
    "model.fit(tf_train_ds, epochs=2, validation_data=tf_valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f9140-f6c9-459e-97a1-cb9a62655f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df395fa6-b444-4f7d-9853-1c0964c301cc",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "Trying the above with pytorch since TensorFlow doesn't support windows when using GPUs anymore. Following along with https://huggingface.co/docs/transformers/tasks/question_answering to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d16e4a7-fc74-49d4-8cbd-af5c36d46340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch can use GPU.\n",
      "Number of CUDA devices: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use GPU.\")\n",
    "    # Additional information\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))  # 0 is the GPU index\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a766c8b-d86c-44b7-aee0-5e36983e8a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccaacd6d368f4076a98650f80376c7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/887 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default-b6a663c53062697f (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\RaviB\\.cache\\huggingface\\datasets\\csv\\default-b6a663c53062697f\\0.0.0\\0d06ce3712951dae7909fb214283b88efab3578535edb5eebd37c498b7a35277...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\RaviB\\.cache\\huggingface\\datasets\\csv\\default-b6a663c53062697f\\0.0.0\\0d06ce3712951dae7909fb214283b88efab3578535edb5eebd37c498b7a35277. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8984299-6c00-49d3-b597-981e56babed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\RaviB\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\RaviB\\\\.cache\\\\huggingface\\\\datasets\\\\squad\\\\plain_text\\\\1.0.0\\\\1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\\\\tmp_nf3mnxj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\shutil.py:825\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\RaviB\\\\.cache\\\\huggingface\\\\datasets\\\\squad\\\\plain_text\\\\1.0.0\\\\1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\\\\tmp_nf3mnxj' -> 'C:\\\\Users\\\\RaviB\\\\.cache\\\\huggingface\\\\datasets\\\\squad\\\\plain_text\\\\1.0.0\\\\1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\\\\cache-e0f87e5cf256064d.arrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m squad \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquad\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain[:5000]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m squad \u001b[38;5;241m=\u001b[39m \u001b[43msquad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#train_dataset = load_dataset('squad', split='train')\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#valid_dataset = load_dataset('squad', split='validation')\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:153\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# don't use self.format since it returns a list of columns for 'columns' even if self_format_columns is None\u001b[39;00m\n\u001b[0;32m    147\u001b[0m new_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    152\u001b[0m }\n\u001b[1;32m--> 153\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(out\u001b[38;5;241m.\u001b[39mcolumn_names))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:163\u001b[0m, in \u001b[0;36mfingerprint.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m             kwargs[fingerprint_name] \u001b[38;5;241m=\u001b[39m update_fingerprint(\n\u001b[0;32m    158\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[0;32m    159\u001b[0m             )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:2098\u001b[0m, in \u001b[0;36mDataset.train_test_split\u001b[1;34m(self, test_size, train_size, shuffle, seed, generator, keep_in_memory, load_from_cache_file, train_indices_cache_file_name, test_indices_cache_file_name, writer_batch_size, train_new_fingerprint, test_new_fingerprint)\u001b[0m\n\u001b[0;32m   2095\u001b[0m     test_indices \u001b[38;5;241m=\u001b[39m permutation[:n_test]\n\u001b[0;32m   2096\u001b[0m     train_indices \u001b[38;5;241m=\u001b[39m permutation[n_test : (n_test \u001b[38;5;241m+\u001b[39m n_train)]\n\u001b[1;32m-> 2098\u001b[0m train_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices_cache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_indices_cache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_new_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m test_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect(\n\u001b[0;32m   2106\u001b[0m     indices\u001b[38;5;241m=\u001b[39mtest_indices,\n\u001b[0;32m   2107\u001b[0m     keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2110\u001b[0m     new_fingerprint\u001b[38;5;241m=\u001b[39mtest_new_fingerprint,\n\u001b[0;32m   2111\u001b[0m )\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_split})\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:153\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# don't use self.format since it returns a list of columns for 'columns' even if self_format_columns is None\u001b[39;00m\n\u001b[0;32m    147\u001b[0m new_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    152\u001b[0m }\n\u001b[1;32m--> 153\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(out\u001b[38;5;241m.\u001b[39mcolumn_names))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:163\u001b[0m, in \u001b[0;36mfingerprint.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m             kwargs[fingerprint_name] \u001b[38;5;241m=\u001b[39m update_fingerprint(\n\u001b[0;32m    158\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[0;32m    159\u001b[0m             )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:1755\u001b[0m, in \u001b[0;36mDataset.select\u001b[1;34m(self, indices, keep_in_memory, indices_cache_file_name, writer_batch_size, new_fingerprint)\u001b[0m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tmp_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1755\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_cache_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# Return new Dataset object\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\shutil.py:846\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m         copy_function(src, real_dst)\n\u001b[1;32m--> 846\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\RaviB\\\\.cache\\\\huggingface\\\\datasets\\\\squad\\\\plain_text\\\\1.0.0\\\\1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41\\\\tmp_nf3mnxj'"
     ]
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\", split=\"train[:5000]\")\n",
    "squad = squad.train_test_split(test_size=0.2)\n",
    "#train_dataset = load_dataset('squad', split='train')\n",
    "#valid_dataset = load_dataset('squad', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2899868e-f02f-432d-8112-48470bd6b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", model_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bc7fc6f-03c7-44e3-848d-4e871c829b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7af0fdc-340c-441a-97a4-d4decd36c85e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dill._dill' has no attribute 'PY3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:1228\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[0;32m   1225\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting finished, running the mapping function on the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_proc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:153\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# don't use self.format since it returns a list of columns for 'columns' even if self_format_columns is None\u001b[39;00m\n\u001b[0;32m    147\u001b[0m new_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    152\u001b[0m }\n\u001b[1;32m--> 153\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(out\u001b[38;5;241m.\u001b[39mcolumn_names))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:157\u001b[0m, in \u001b[0;36mfingerprint.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(fingerprint_name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m             kwargs_for_fingerprint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfingerprint_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fingerprint_name\n\u001b[1;32m--> 157\u001b[0m             kwargs[fingerprint_name] \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_fingerprint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fingerprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_for_fingerprint\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m    163\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:105\u001b[0m, in \u001b[0;36mupdate_fingerprint\u001b[1;34m(fingerprint, transform, transform_args)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(transform_args):\n\u001b[0;32m    104\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(key)\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mhasher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform_args\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:57\u001b[0m, in \u001b[0;36mHasher.update\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:53\u001b[0m, in \u001b[0;36mHasher.hash\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch[\u001b[38;5;28mtype\u001b[39m(value)](\u001b[38;5;28mcls\u001b[39m, value)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:46\u001b[0m, in \u001b[0;36mHasher.hash_default\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash_default\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value):\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhash_bytes(\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\utils\\py_utils.py:367\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    365\u001b[0m file \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _no_cache_fields(obj):\n\u001b[1;32m--> 367\u001b[0m     \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\utils\\py_utils.py:339\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"pickle an object to a file\"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[43mPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:420\u001b[0m, in \u001b[0;36mPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace_setup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 420\u001b[0m     \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:1985\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict:\n\u001b[0;32m   1983\u001b[0m     state \u001b[38;5;241m=\u001b[39m state, state_dict\n\u001b[1;32m-> 1985\u001b[0m \u001b[43m_save_with_postproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_create_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__code__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__defaults__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostproc_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostproc_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# Lift closure cell update to earliest function (#458)\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _postproc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:1098\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     pickler\u001b[38;5;241m.\u001b[39m_postproc[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m postproc_list\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO: Use state_setter in Python 3.8 to allow for faster cPickle implementations\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_pickler_dill:\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;66;03m# pickler.x -= 1\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;66;03m# print(pickler.x*' ', 'pop', obj, id(obj))\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m     postproc \u001b[38;5;241m=\u001b[39m pickler\u001b[38;5;241m.\u001b[39m_postproc\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mid\u001b[39m(obj))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     save(func)\n\u001b[1;32m--> 692\u001b[0m     \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m     write(REDUCE)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:902\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    900\u001b[0m write(MARK)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 902\u001b[0m     \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;66;03m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     get \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(memo[\u001b[38;5;28mid\u001b[39m(obj)][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\utils\\py_utils.py:395\u001b[0m, in \u001b[0;36m_save_code\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m    393\u001b[0m co_firstlineno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mco_filename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mco_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<lambda>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mco_firstlineno\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# The rest is the same as in the original dill implementation\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPY3\u001b[49m:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mco_posonlyargcount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    397\u001b[0m         args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    398\u001b[0m             obj\u001b[38;5;241m.\u001b[39mco_argcount,\n\u001b[0;32m    399\u001b[0m             obj\u001b[38;5;241m.\u001b[39mco_posonlyargcount,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m             obj\u001b[38;5;241m.\u001b[39mco_cellvars,\n\u001b[0;32m    414\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dill._dill' has no attribute 'PY3'"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6c247-7f3f-4444-a890-68e6c4532938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79740742-f16a-4742-98e5-f0fbd99f714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", model_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f0d9152-d18b-4539-83cd-bde88bfa7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(example):\n",
    "    passage = example[\"context\"]\n",
    "    question = example[\"question\"]\n",
    "    answer = example[\"answers\"][\"text\"][0]\n",
    "\n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus} </s>\"\n",
    "    \n",
    "    input_text = f\"question: {question} context: {passage}\"\n",
    "\n",
    "    \n",
    "    target_text = answer\n",
    "\n",
    "    \n",
    "    return tokenizer(input_text, padding=\"max_length\", truncation=True), tokenizer(target_text, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "668a1314-120c-4f2c-a3fe-d0fc77018988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps:  21900\n",
      "Total Validation Steps:  2643\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "warmup_steps = 1e4\n",
    "batch_size = 4\n",
    "encoder_max_len = 250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000\n",
    "ntrain = len(train_dataset)\n",
    "nvalid = len(valid_dataset)\n",
    "steps = int(np.ceil(ntrain/batch_size))\n",
    "valid_steps = int(np.ceil(nvalid/batch_size))\n",
    "print(\"Total Steps: \", steps)\n",
    "print(\"Total Validation Steps: \", valid_steps)\n",
    "\n",
    "def encode(example,\n",
    "           encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "  \n",
    "    context = example['context']\n",
    "    question = example['question']\n",
    "    answer = example['answers']['text']\n",
    "  \n",
    "    question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += f\" context: {str(context)} </s>\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus} </s>\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention}\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9eb175c6-a6dc-487b-9ea8-b8f313815cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#squad[\"train\"]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16bcfc1b-dc97-4280-8b2a-76553a9d0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'dill._dill' has no attribute 'PY3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_ds\u001b[38;5;241m=\u001b[39m  \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m valid_ds\u001b[38;5;241m=\u001b[39m  valid_dataset\u001b[38;5;241m.\u001b[39mmap(encode)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:1228\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[0;32m   1225\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting finished, running the mapping function on the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_proc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\arrow_dataset.py:153\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# don't use self.format since it returns a list of columns for 'columns' even if self_format_columns is None\u001b[39;00m\n\u001b[0;32m    147\u001b[0m new_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    152\u001b[0m }\n\u001b[1;32m--> 153\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(new_format[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(out\u001b[38;5;241m.\u001b[39mcolumn_names))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:157\u001b[0m, in \u001b[0;36mfingerprint.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(fingerprint_name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m             kwargs_for_fingerprint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfingerprint_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fingerprint_name\n\u001b[1;32m--> 157\u001b[0m             kwargs[fingerprint_name] \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_fingerprint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fingerprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_for_fingerprint\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m    163\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:105\u001b[0m, in \u001b[0;36mupdate_fingerprint\u001b[1;34m(fingerprint, transform, transform_args)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(transform_args):\n\u001b[0;32m    104\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(key)\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mhasher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform_args\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:57\u001b[0m, in \u001b[0;36mHasher.update\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:53\u001b[0m, in \u001b[0;36mHasher.hash\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch[\u001b[38;5;28mtype\u001b[39m(value)](\u001b[38;5;28mcls\u001b[39m, value)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\fingerprint.py:46\u001b[0m, in \u001b[0;36mHasher.hash_default\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash_default\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value):\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhash_bytes(\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\utils\\py_utils.py:367\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    365\u001b[0m file \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _no_cache_fields(obj):\n\u001b[1;32m--> 367\u001b[0m     \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\utils\\py_utils.py:339\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"pickle an object to a file\"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[43mPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:420\u001b[0m, in \u001b[0;36mPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace_setup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 420\u001b[0m     \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:1985\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict:\n\u001b[0;32m   1983\u001b[0m     state \u001b[38;5;241m=\u001b[39m state, state_dict\n\u001b[1;32m-> 1985\u001b[0m \u001b[43m_save_with_postproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_create_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__code__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__defaults__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostproc_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostproc_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# Lift closure cell update to earliest function (#458)\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _postproc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:1098\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     pickler\u001b[38;5;241m.\u001b[39m_postproc[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m postproc_list\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO: Use state_setter in Python 3.8 to allow for faster cPickle implementations\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_pickler_dill:\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;66;03m# pickler.x -= 1\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;66;03m# print(pickler.x*' ', 'pop', obj, id(obj))\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m     postproc \u001b[38;5;241m=\u001b[39m pickler\u001b[38;5;241m.\u001b[39m_postproc\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mid\u001b[39m(obj))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     save(func)\n\u001b[1;32m--> 692\u001b[0m     \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m     write(REDUCE)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;66;03m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:902\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    900\u001b[0m write(MARK)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m--> 902\u001b[0m     \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(obj) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;66;03m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     get \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(memo[\u001b[38;5;28mid\u001b[39m(obj)][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\dill\\_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[1;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\edamam\\Lib\\site-packages\\datasets\\utils\\py_utils.py:395\u001b[0m, in \u001b[0;36m_save_code\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m    393\u001b[0m co_firstlineno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mco_filename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mco_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<lambda>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mco_firstlineno\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# The rest is the same as in the original dill implementation\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPY3\u001b[49m:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mco_posonlyargcount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    397\u001b[0m         args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    398\u001b[0m             obj\u001b[38;5;241m.\u001b[39mco_argcount,\n\u001b[0;32m    399\u001b[0m             obj\u001b[38;5;241m.\u001b[39mco_posonlyargcount,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m             obj\u001b[38;5;241m.\u001b[39mco_cellvars,\n\u001b[0;32m    414\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dill._dill' has no attribute 'PY3'"
     ]
    }
   ],
   "source": [
    "train_ds=  train_dataset.map(encode)\n",
    "valid_ds=  valid_dataset.map(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28e531-9f35-4864-a458-d98786ea8591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
